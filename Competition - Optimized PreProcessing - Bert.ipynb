{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducition\n",
    "The following code contains the creation and training of an RNN Model using Keras and TensorFlow. The project was originally started in Kaggle but was moved to Jupyter Notebook so as to utilize hardware acceleration. The aim of the model is to decide whether tweets entered are one of eight emotions. The emotions are as followed: {'joy', 'surprise', 'sadness', 'anger', 'trust', 'fear', 'disgust', 'anticipation'}. Many of the porcesses taken and utilized were thanks to the GPU-Accelerated performance of the Jupyter Notebook. With that I was able to perform more epochs as well as create more versions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-11T09:34:12.995737Z",
     "iopub.status.busy": "2022-11-11T09:34:12.994307Z",
     "iopub.status.idle": "2022-11-11T09:34:13.027580Z",
     "shell.execute_reply": "2022-11-11T09:34:13.026564Z",
     "shell.execute_reply.started": "2022-11-11T09:34:12.995536Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Importing Files\n",
    "Due to the JSON being a Nested Json, the original df did not fully contain the information needed. Due to this another dataframe was created with json_normalize so as to have the tweet_id, and the text, which were very importan. The tweet_id was necessary so as to add combine the other dataframes that contained the training and test data. The reason for this was so as to have the dataframe be able to share the tweet text via the tweet_id. Afterwards, separate dataframes where created to have the Training and Testing Data Separate from each other, as well as the emotion labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T09:34:13.036012Z",
     "iopub.status.busy": "2022-11-11T09:34:13.035360Z",
     "iopub.status.idle": "2022-11-11T09:34:45.663145Z",
     "shell.execute_reply": "2022-11-11T09:34:45.661855Z",
     "shell.execute_reply.started": "2022-11-11T09:34:13.035977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score          _index                                            _source  \\\n",
       "0     391  hashtag_tweets  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1     433  hashtag_tweets  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2     232  hashtag_tweets  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3     376  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4     989  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "\n",
       "            _crawldate   _type  \n",
       "0  2015-05-23 11:42:47  tweets  \n",
       "1  2016-01-28 04:52:09  tweets  \n",
       "2  2017-12-25 04:39:20  tweets  \n",
       "3  2016-01-24 23:53:05  tweets  \n",
       "4  2016-01-08 17:18:59  tweets  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Twitter DF From Json Files\n",
    "twitterDM = \"Twitter/tweets_DM.json\"\n",
    "twitter_df = pd.read_json(twitterDM, lines=True)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T09:34:45.666383Z",
     "iopub.status.busy": "2022-11-11T09:34:45.665605Z",
     "iopub.status.idle": "2022-11-11T09:35:03.199789Z",
     "shell.execute_reply": "2022-11-11T09:35:03.198661Z",
     "shell.execute_reply.started": "2022-11-11T09:34:45.666316Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galve\\AppData\\Local\\Temp\\ipykernel_4328\\3164084898.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  twitterDM_df.columns = twitterDM_df.columns.str.replace('^tweet.', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                hashtags  tweet_id  \\\n",
       "0                             [Snapchat]  0x376b20   \n",
       "1          [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                           [bibleverse]  0x28b412   \n",
       "3                                     []  0x1cd5b0   \n",
       "4                                     []  0x2de201   \n",
       "...                                  ...       ...   \n",
       "1867530  [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "1867531                               []  0x29d0cb   \n",
       "1867532                               []  0x2a6a4f   \n",
       "1867533                               []  0x24faed   \n",
       "1867534                    [Sundayvibes]  0x34be8c   \n",
       "\n",
       "                                                      text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha 😂😂😂 <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...  \n",
       "1867531  I swear all this hard work gone pay off one da...  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the Tweet Inform From the Source Column of the Original DF\n",
    "twitterDM_df = pd.json_normalize(twitter_df._source, record_prefix=None)\n",
    "twitterDM_df.columns = twitterDM_df.columns.str.replace('^tweet.', '')\n",
    "twitterDM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T09:35:03.201496Z",
     "iopub.status.busy": "2022-11-11T09:35:03.201135Z",
     "iopub.status.idle": "2022-11-11T09:35:04.855421Z",
     "shell.execute_reply": "2022-11-11T09:35:04.853997Z",
     "shell.execute_reply.started": "2022-11-11T09:35:03.201463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "0        0x28cc61           test\n",
       "1        0x29e452          train\n",
       "2        0x2b3819          train\n",
       "3        0x2db41f           test\n",
       "4        0x2a2acc          train\n",
       "...           ...            ...\n",
       "1867530  0x227e25          train\n",
       "1867531  0x293813          train\n",
       "1867532  0x1e1a7e          train\n",
       "1867533  0x2156a5          train\n",
       "1867534  0x2bb9d2          train\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Data_Identification DF\n",
    "twitterID = \"Twitter/data_identification.csv\"\n",
    "twitid_df = pd.read_csv(twitterID)\n",
    "twitid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T09:35:04.859500Z",
     "iopub.status.busy": "2022-11-11T09:35:04.858634Z",
     "iopub.status.idle": "2022-11-11T09:35:06.209585Z",
     "shell.execute_reply": "2022-11-11T09:35:06.207912Z",
     "shell.execute_reply.started": "2022-11-11T09:35:04.859455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>0x38dba0</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>0x300ea2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>0x360b99</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>0x22eecf</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>0x2fb282</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       emotion\n",
       "0        0x3140b1       sadness\n",
       "1        0x368b73       disgust\n",
       "2        0x296183  anticipation\n",
       "3        0x2bd6e1           joy\n",
       "4        0x2ee1dd  anticipation\n",
       "...           ...           ...\n",
       "1455558  0x38dba0           joy\n",
       "1455559  0x300ea2           joy\n",
       "1455560  0x360b99          fear\n",
       "1455561  0x22eecf           joy\n",
       "1455562  0x2fb282  anticipation\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Emotion DF\n",
    "emotion = \"Twitter/emotion.csv\"\n",
    "twitemo_df = pd.read_csv(emotion)\n",
    "twitemo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T09:35:06.212287Z",
     "iopub.status.busy": "2022-11-11T09:35:06.211881Z",
     "iopub.status.idle": "2022-11-11T09:35:15.227115Z",
     "shell.execute_reply": "2022-11-11T09:35:15.224069Z",
     "shell.execute_reply.started": "2022-11-11T09:35:06.212247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>[]</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                         hashtags  \\\n",
       "0        0x376b20                       [Snapchat]   \n",
       "1        0x2d5350    [freepress, TrumpLegacy, CNN]   \n",
       "2        0x28b412                     [bibleverse]   \n",
       "3        0x1cd5b0                               []   \n",
       "4        0x2de201                               []   \n",
       "...           ...                              ...   \n",
       "1867530  0x316b80  [mixedfeeling, butimTHATperson]   \n",
       "1867531  0x29d0cb                               []   \n",
       "1867532  0x2a6a4f                               []   \n",
       "1867533  0x24faed                               []   \n",
       "1867534  0x34be8c                    [Sundayvibes]   \n",
       "\n",
       "                                                      text identification  \\\n",
       "0        People who post \"add me on #Snapchat\" must be ...          train   \n",
       "1        @brianklaas As we see, Trump is dangerous to #...          train   \n",
       "2        Confident of your obedience, I write to you, k...           test   \n",
       "3                      Now ISSA is stalking Tasha 😂😂😂 <LH>          train   \n",
       "4        \"Trust is not the same as faith. A friend is s...           test   \n",
       "...                                                    ...            ...   \n",
       "1867530  When you buy the last 2 tickets remaining for ...           test   \n",
       "1867531  I swear all this hard work gone pay off one da...           test   \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...           test   \n",
       "1867533  Ah, corporate life, where you can date <LH> us...          train   \n",
       "1867534             Blessed to be living #Sundayvibes <LH>          train   \n",
       "\n",
       "              emotion  \n",
       "0        anticipation  \n",
       "1             sadness  \n",
       "2                 NaN  \n",
       "3                fear  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "1867530           NaN  \n",
       "1867531           NaN  \n",
       "1867532           NaN  \n",
       "1867533           joy  \n",
       "1867534           joy  \n",
       "\n",
       "[1867535 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining DataFrames\n",
    "dfs = [twitterDM_df,twitid_df,twitemo_df]\n",
    "twitcom_df = pd.concat([x.set_index('tweet_id') for x in dfs], axis=1).reset_index()\n",
    "twitcom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T09:35:15.229849Z",
     "iopub.status.busy": "2022-11-11T09:35:15.229252Z",
     "iopub.status.idle": "2022-11-11T09:35:16.373928Z",
     "shell.execute_reply": "2022-11-11T09:35:16.372557Z",
     "shell.execute_reply.started": "2022-11-11T09:35:15.229789Z"
    }
   },
   "outputs": [],
   "source": [
    "#Extracting the Training and testing Data\n",
    "twitTrain_df = twitcom_df.loc[twitcom_df['identification'] == 'train']\n",
    "twitTest_df = twitcom_df.loc[twitcom_df['identification'] == 'test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexes had to be reset for other uses after everything was separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T09:35:16.376575Z",
     "iopub.status.busy": "2022-11-11T09:35:16.376043Z",
     "iopub.status.idle": "2022-11-11T09:35:16.401033Z",
     "shell.execute_reply": "2022-11-11T09:35:16.399110Z",
     "shell.execute_reply.started": "2022-11-11T09:35:16.376524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>[]</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>0x321566</td>\n",
       "      <td>[NoWonder, Happy]</td>\n",
       "      <td>I'm SO HAPPY!!! #NoWonder the name of this sho...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>0x38959e</td>\n",
       "      <td>[]</td>\n",
       "      <td>In every circumtance I'd like to be thankful t...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>0x2cbca6</td>\n",
       "      <td>[blessyou]</td>\n",
       "      <td>there's currently two girls walking around the...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                       hashtags  \\\n",
       "0        0x376b20                     [Snapchat]   \n",
       "1        0x2d5350  [freepress, TrumpLegacy, CNN]   \n",
       "2        0x1cd5b0                             []   \n",
       "3        0x1d755c      [authentic, LaughOutLoud]   \n",
       "4        0x2c91a8                             []   \n",
       "...           ...                            ...   \n",
       "1455558  0x321566              [NoWonder, Happy]   \n",
       "1455559  0x38959e                             []   \n",
       "1455560  0x2cbca6                     [blessyou]   \n",
       "1455561  0x24faed                             []   \n",
       "1455562  0x34be8c                  [Sundayvibes]   \n",
       "\n",
       "                                                      text identification  \\\n",
       "0        People who post \"add me on #Snapchat\" must be ...          train   \n",
       "1        @brianklaas As we see, Trump is dangerous to #...          train   \n",
       "2                      Now ISSA is stalking Tasha 😂😂😂 <LH>          train   \n",
       "3        @RISKshow @TheKevinAllison Thx for the BEST TI...          train   \n",
       "4             Still waiting on those supplies Liscus. <LH>          train   \n",
       "...                                                    ...            ...   \n",
       "1455558  I'm SO HAPPY!!! #NoWonder the name of this sho...          train   \n",
       "1455559  In every circumtance I'd like to be thankful t...          train   \n",
       "1455560  there's currently two girls walking around the...          train   \n",
       "1455561  Ah, corporate life, where you can date <LH> us...          train   \n",
       "1455562             Blessed to be living #Sundayvibes <LH>          train   \n",
       "\n",
       "              emotion  \n",
       "0        anticipation  \n",
       "1             sadness  \n",
       "2                fear  \n",
       "3                 joy  \n",
       "4        anticipation  \n",
       "...               ...  \n",
       "1455558           joy  \n",
       "1455559           joy  \n",
       "1455560           joy  \n",
       "1455561           joy  \n",
       "1455562           joy  \n",
       "\n",
       "[1455563 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reseting and Testing Train Dataframe\n",
    "twitTrain_df.reset_index(drop=True, inplace=True)\n",
    "twitTrain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T09:35:16.404728Z",
     "iopub.status.busy": "2022-11-11T09:35:16.403472Z",
     "iopub.status.idle": "2022-11-11T09:35:16.429745Z",
     "shell.execute_reply": "2022-11-11T09:35:16.428155Z",
     "shell.execute_reply.started": "2022-11-11T09:35:16.404670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>[]</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"For this is the message that ye heard from th...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"There is a lad here, which hath five barley l...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>[]</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id                           hashtags  \\\n",
       "0       0x28b412                       [bibleverse]   \n",
       "1       0x2de201                                 []   \n",
       "2       0x218443  [materialism, money, possessions]   \n",
       "3       0x2939d5               [GodsPlan, GodsWork]   \n",
       "4       0x26289a                                 []   \n",
       "...          ...                                ...   \n",
       "411967  0x2913b4                                 []   \n",
       "411968  0x2a980e                                 []   \n",
       "411969  0x316b80    [mixedfeeling, butimTHATperson]   \n",
       "411970  0x29d0cb                                 []   \n",
       "411971  0x2a6a4f                                 []   \n",
       "\n",
       "                                                     text identification  \\\n",
       "0       Confident of your obedience, I write to you, k...           test   \n",
       "1       \"Trust is not the same as faith. A friend is s...           test   \n",
       "2       When do you have enough ? When are you satisfi...           test   \n",
       "3       God woke you up, now chase the day #GodsPlan #...           test   \n",
       "4       In these tough times, who do YOU turn to as yo...           test   \n",
       "...                                                   ...            ...   \n",
       "411967  \"For this is the message that ye heard from th...           test   \n",
       "411968  \"There is a lad here, which hath five barley l...           test   \n",
       "411969  When you buy the last 2 tickets remaining for ...           test   \n",
       "411970  I swear all this hard work gone pay off one da...           test   \n",
       "411971  @Parcel2Go no card left when I wasn't in so I ...           test   \n",
       "\n",
       "       emotion  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "411967     NaN  \n",
       "411968     NaN  \n",
       "411969     NaN  \n",
       "411970     NaN  \n",
       "411971     NaN  \n",
       "\n",
       "[411972 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reseting and Testing Test Dataframe\n",
    "twitTest_df.reset_index(drop=True, inplace=True)\n",
    "twitTest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = twitTrain_df[['text','emotion']]\n",
    "tweets_test = twitTest_df[['text', 'emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@sydbell1 @strut4cancer £50 donates to Macmillan       👍😎👌 <LH> !!', 'joy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train.text[50],tweets_train.emotion[50],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing\n",
    "Originally, no preprocessing was done. This was becuase I thought that even without it I would still be able to get a 0.7 or above accuracy. An assumption that proved to be true. With that being said, for some reason or another, I decided to add preprocessing of the data to see how far I could take this. The preprocessing step was mostly to remove usernames, one letter words, unnecessary stopwords, spaces, the lower of text for uniformity and word lemmetimization. I also wanted to do more but I think I did enough. (I got tired). Also tested whether or not removing stop words performed better or worse. You can tell which one I chose based on int's inclusion/exclusion in th immediate following data. Plan to utilize emoji detection as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# PREVIOUS VERSION####################################\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# import re\n",
    "# import emoji \n",
    "\n",
    "# def preprocess_text(Tweet):\n",
    "#         #Removes Username\n",
    "#         Tweet = re.sub('@[^\\s]+','',Tweet)\n",
    "        \n",
    "#         #Demojize Emojis\n",
    "#         Tweet = emoji.demojize(Tweet)\n",
    "#         Tweet = Tweet.replace(\":\",\" \")\n",
    "#         Tweet = ' '.join(Tweet.split())\n",
    "        \n",
    "#         #Removes LH\n",
    "#         Tweet = re.sub('<[^\\s]+','',Tweet)\n",
    "        \n",
    "#         #Removes Hashtage\n",
    "#         Tweet = re.sub('#','',Tweet)\n",
    "        \n",
    "#         # Remove puntuations and numbers\n",
    "#         Tweet = re.sub('[^a-zA-Z]', ' ', Tweet)\n",
    "               \n",
    "#         # Remove single characters\n",
    "#         Tweet = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', Tweet)\n",
    "\n",
    "#         # remove multiple spaces\n",
    "#         Tweet = re.sub(r'\\s+', ' ', Tweet)\n",
    "#         Tweet = Tweet.lower()\n",
    "        \n",
    "#         # Convert Text sentence to Tokens\n",
    "#         Tweet = word_tokenize(Tweet)\n",
    "       \n",
    "#         #Remove unncecessay stopwords #####Disabled#####\n",
    "#         stop_words = stopwords.words('english')\n",
    "#         filtered_text = []\n",
    "#         for t in Tweet:\n",
    "#           if t not in stop_words:\n",
    "#             filtered_text.append(t)\n",
    "\n",
    "#         # Word lemmatization\n",
    "#         wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#         processed_text1 = []\n",
    "#         for t in filtered_text:\n",
    "#             word1 = wordnet_lemmatizer.lemmatize(t, pos=\"n\")\n",
    "#             word2 = wordnet_lemmatizer.lemmatize(word1, pos=\"v\")\n",
    "#             word3 = wordnet_lemmatizer.lemmatize(word2, pos=(\"a\"))\n",
    "#             processed_text1.append(word3)\n",
    "\n",
    "#         result = \"\"\n",
    "#         for word in processed_text1:\n",
    "#             result = result + word + \" \"\n",
    "#         result = result.rstrip() \n",
    "        \n",
    "#         return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Optimized Pre-Processing\n",
    "After giving up on Pre-Processing aside from Keras, I decide to try it again. The Following method was ahieved through an accidental eureka moment when looking for other Tokenizers and Find Twitter Tokenizer that meshed well with the rest of the code as well as the Keras Module. The follwing model performs better than the previous one by doing everything the previous one did but with inclusion of the emojis themselves. While it may have some very rare symbols issues.\n",
    "Update:\n",
    "The issue with the symbol issue that plaugued and significantly reduced to capabilities of the model has been resolved in the new optimized model. This preprocessing converts emojis to connected words, remove username before twittertokenization and hashtag symbols, so that anyword that would have been negatively impacted such as stop words as well has been made to be taken care of. Stop words also removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# UPDATED VERSION WITH BETTER RESULTS###########################\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from cleantext import clean\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "\n",
    "def preprocess_text(Tweet):\n",
    "    #Removes LH\n",
    "    Tweet = re.sub('<[^\\s]+','',Tweet)\n",
    "    \n",
    "    #Removes Hashtage\n",
    "    Tweet = re.sub('#','',Tweet)\n",
    "    \n",
    "    #Removes Numbers\n",
    "    Tweet =re.sub(r'[0-9]+', '', Tweet)\n",
    "        \n",
    "    #Removes Currency and Emojis\n",
    "    Tweet = clean(Tweet, no_currency_symbols=True, replace_with_currency_symbol=\"\", no_emoji=True)\n",
    "    \n",
    "    #Convets emoji to text\n",
    "    #Tweet = emoji.demojize(Tweet)\n",
    "    #Tweet = re.sub('_','',Tweet)\n",
    "    \n",
    "    #Remove @Username\n",
    "    Tweet = re.sub('@[^\\s]+','',Tweet)\n",
    "    \n",
    "    #Remove Punctation\n",
    "    Tweet = re.sub(r'[^\\w\\s]',' ',Tweet)\n",
    "   \n",
    "\n",
    "    #Tokenizer Using Tweet Tokenizer\n",
    "    tknzr = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=False)\n",
    "    Tweet_t = tknzr.tokenize(Tweet)\n",
    "    \n",
    "    #Stop Words Removal\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_text = []\n",
    "    for t in Tweet_t:\n",
    "        if t not in stop_words:\n",
    "            filtered_text.append(t)\n",
    "            \n",
    "    # Word lemmatization\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    processed_text1 = []\n",
    "    for t in filtered_text:\n",
    "        word1 = wordnet_lemmatizer.lemmatize(t, pos=\"n\")\n",
    "        word2 = wordnet_lemmatizer.lemmatize(word1, pos=\"v\")\n",
    "        word3 = wordnet_lemmatizer.lemmatize(word2, pos=(\"a\"))\n",
    "        processed_text1.append(word3)\n",
    "    \n",
    "    result = \"\"\n",
    "    for word in processed_text1:\n",
    "        result = result + word + \" \"\n",
    "    result = result.rstrip() \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean  = []\n",
    "for c in tweets_train.text:\n",
    "    train_clean.append(preprocess_text(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean  = []\n",
    "for c in tweets_test.text:\n",
    "    test_clean.append(preprocess_text(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people post add snapchat must dehydrate cuz man',\n",
       " 'know research butterfly predictive text autocorrects butterfly justgradstudentthings ecology',\n",
       " 'never half man pat tillman',\n",
       " 'follow next hour iphonex windians clevelandindians mothermovie detroithomecoming retweeet bignews',\n",
       " 'way truth life',\n",
       " 'donate macmillan',\n",
       " 'want frank ocean phone cover',\n",
       " 'anyone want talk anything hit suicide',\n",
       " 'stop progressive change make whilst battle doubt grind make settle trust jesus',\n",
       " 'thing world powerful positive push smile world optimism richard devos givehope givetariro',\n",
       " 'hi suzyq like sibling',\n",
       " 'want right',\n",
       " 'fdg',\n",
       " 'mia',\n",
       " 'follower bot faketrumpfan sad',\n",
       " 'okay do need vent twitter',\n",
       " 'thank follow glad connect wish best life',\n",
       " 'anything scary restaraunt fountain drink dispenser cough middle fill',\n",
       " 'always take place want',\n",
       " 'people never get smh alive well livetheglory',\n",
       " 'well something right',\n",
       " 'lol hahah one',\n",
       " 'thank friyay',\n",
       " 'ahhh feel free happy queer today good know happen trans queer',\n",
       " 'toxicity great album workout nomorequitting',\n",
       " 'reason world standard believe believe anyway todd white good night everyone believe godisstillgood',\n",
       " 'grateful',\n",
       " 'bisexual stream',\n",
       " 'omg must awesome',\n",
       " 'god bless amaze life godisgood',\n",
       " 'grow trentonnj know trump long ago little positive fast shady deal bully self aggrandizement',\n",
       " 'believe even tweet father do woman',\n",
       " 'great time cousin grandma live tuesdaymotivation',\n",
       " 'angel lead single instead helikethat nd',\n",
       " 'congratulation sirmo farah great achievement namely first bos entry guy give hard',\n",
       " 'listen mahiya remix reminisce old memory awarapan',\n",
       " '',\n",
       " 'love see hand god defense helovesme godislove godspeace',\n",
       " 'get respect child self wild',\n",
       " 'yup happen last week',\n",
       " 'expect nudity watch girl trip flight',\n",
       " 'people tell u good thing ur kid make u feel u something right amaze parent even kaidyn',\n",
       " 'moment enough moment need good morning',\n",
       " 'sure way fail bedetermined succeed inspiration qotd motivation success',\n",
       " 'every boy want good girl bad follofollo follofolloback say think rt',\n",
       " 'get excite see follow aaron paul real',\n",
       " 'childfree last night go pub hubby',\n",
       " '',\n",
       " 'bad game season yet liverpool beat u munliv',\n",
       " 'get review game compare thank much',\n",
       " 'available sc',\n",
       " 'fat gay',\n",
       " 'bad face committee',\n",
       " 'yankee come yankee',\n",
       " 'rise grind rackingandstacking',\n",
       " 'close sell lot eurusd pip total today pip',\n",
       " 'answer work believe one send john yoke easy matt christian faith',\n",
       " 'success see hardwork see difference man woman indianwomencricketteam',\n",
       " 'close sell lot eurusd pip total today pip',\n",
       " 'take people say seriously',\n",
       " 'cdn believe world full ppl like leader prayforall prayforpeace',\n",
       " 'someone bus head phone alll way plug enjoy lady antebellum',\n",
       " 'people think earth moon sun amaze look sky let feel god presence realize creation',\n",
       " 'pliz drop thank',\n",
       " 'moment life life november',\n",
       " 'rip chesterbennington awesome singer',\n",
       " 'still alive okay imokay',\n",
       " 'dream leave backpack trip buy new sleep bag mat waterproof noisy',\n",
       " 'breakingnews woman flint promote interview flintwatercrisis speak promote film disgrace',\n",
       " 'jk rowling goat bbbeasts bitch',\n",
       " 'hundred dead wound terroristattack world timidly silent responsive somalia waxaanahaysomaali',\n",
       " 'love girl jam hit itunes please',\n",
       " 'god command remain relevant change change u supersoulsunday',\n",
       " 'bore',\n",
       " 'crucify two thief regret yesterday fear tomorrow fulton oursler regret future past life',\n",
       " 'workplace safety old idea one follow bestmarine safety safetyfirst',\n",
       " 'saw mountain u love',\n",
       " 'perseverance fail nineteen time succeed twentieth motivation',\n",
       " 'always pleasure cecilia photography wish lovely day friend',\n",
       " 'endthefed get rid dodd_frank ditch something hope',\n",
       " 'really bad day buy dq blizzard make grill cheese',\n",
       " 'profile pic',\n",
       " 'faith hope last forever great love corinthian',\n",
       " 'wait girlfriend',\n",
       " 'college equation like x sded e x',\n",
       " 'lord lift pit put new song mouth song praise god p',\n",
       " 'soul truly human come presentmoment soul trueself soulpurpose human iam',\n",
       " 'healthy food point rewardseatinghealthy globalag farmtotable startup',\n",
       " 'definitely serious time',\n",
       " 'close sama light dengan open swear would one main highlight malaysia',\n",
       " 'forgiveness set free live life deserve excerpt book doitanyway singlemom',\n",
       " 'definitely start diet today bikini body come pendingsize',\n",
       " 'vote decimate medicaid help many constituent protectmedicaid',\n",
       " 'next time spend fams last night orl sure whereswalt magicless',\n",
       " 'question day fave place house work outdoorsy sort magneticbranding',\n",
       " 'feel fab greatful love life health family friendship think today tomorrow always',\n",
       " 'amaze finally share aworldatwar see impact beautifully craft show judithparis',\n",
       " 'feel cat could care le christmas tree shiny ornament',\n",
       " 'massive thank sport ambassador support abbeyfield sport day couldnothavedoneitwithoutyou',\n",
       " 'u r truly amazayn best person world mind follow happy person',\n",
       " 'go competition anyone bless man fight anything inside refinery goody',\n",
       " 'get heaven day rejoice see jesus sing shout victory',\n",
       " 'luv waaay extra cause ion wanna recognize rest different',\n",
       " 'husband good bestvacation',\n",
       " 'life beautiful stop appreciate thanksbetogod life lessonslearned yah',\n",
       " 'recliner way see movie day',\n",
       " 'true love never happy end becse true love never end neverendinglove onesidedlove thursdaythoughts',\n",
       " 'detain u',\n",
       " 'flex flex remix straight yes',\n",
       " 'thankful god unconditional love though feel come go god love u cslewis agape',\n",
       " 'make somehow survive debt owe make recovery nrns justfortoday',\n",
       " 'mourn console mourn zion give ash oil mourn',\n",
       " 'as bbw pussy skype girl horny jacobgigs',\n",
       " 'work tourdetonka wave foam finger waconia lol',\n",
       " 'always people access toothbrush feel amuse',\n",
       " 'wow see world partisan way glass half full mnleg',\n",
       " 'go extent satisfy keep detail totally obedient thing time samuel',\n",
       " 'weinstein predator oreilly predator long make money though people look way',\n",
       " 'else credit diply life',\n",
       " 'heart get break til open stay strong stay true love',\n",
       " 'healty everything make',\n",
       " 'another',\n",
       " 'watch random youtube boom lil baby everybody love clip pop',\n",
       " 'tweet snap back k whatever lrskr',\n",
       " 'circleoflights home youtube',\n",
       " 'someone wanna doll help get morefollowers wantmore',\n",
       " 'god open door ya complain thankful newbeginnings changeiscoming',\n",
       " 'hate beget hate strife produce strife alone overcome thankyouveterans love serve country heal',\n",
       " 'place one night stand tuesday go get nothing wow',\n",
       " 'office big priority fakeleader',\n",
       " 'nice education afford austerity u brit princesscharlotte',\n",
       " 'gotta stay focus rhod',\n",
       " 'word',\n",
       " 'make mind selena everyone confuse af ig theweekend justinbieber',\n",
       " 'happy prime current hit peak high school',\n",
       " 'issa really blow',\n",
       " 'curious pick quote tweet',\n",
       " 'hear evil see evil',\n",
       " 'million infernal prize anthropithecci',\n",
       " 'dreambig matter hard impossible make easy possible work faith',\n",
       " 'attention producer need dark demonic emo beat asap email discrespectful genre accept',\n",
       " 'lord touch mind heart body thank simpleprayer',\n",
       " 'supa dupa pump fca lakeside high school morning warrior pregame jesusisbetter',\n",
       " 'disappointment inescapable christ u always life let u lift u',\n",
       " 'much botox face fonda parton gasp disappoint tomlin',\n",
       " 'man hop scene real lmao',\n",
       " 'lift also pack stuff alone prepare move still decorate place july th supermom bless',\n",
       " 'year late finally get damn name tag work week late get brand new logo fuckmeright',\n",
       " 'puppy literally read',\n",
       " 'close sell lot eurusd pip total today pip',\n",
       " 'well month turn interest lot happen th guess see happen lie truthhurts',\n",
       " 'follow enjoy night day cheer',\n",
       " 'different costume',\n",
       " 'half hour hold update upinarms',\n",
       " 'month try figure pardon douchenozzle',\n",
       " 'oho nice interest hope fan buy comic',\n",
       " 'number expression word mouth corithians gltchurch',\n",
       " 'wizard quidditch world cup glamping harrypotter harrypotter',\n",
       " 'thank u decorative wall love wall wallfashion springdiaries beautiful',\n",
       " 'ur sad right watch heartbeat sooo cute',\n",
       " 'yes komal one get back b im obsess gratefulandblessed',\n",
       " 'god glory blame jesus timeshavechanged',\n",
       " 'hey eriot slupper thank follow help endeavor ur day',\n",
       " 'sorry witness person amount std must pass',\n",
       " 'realize wowowow know exactly say get people think good one',\n",
       " 'people get frustrate ask life reason lot people know live',\n",
       " 'mag spicy noodle challenge mi next week',\n",
       " 'twitter feel extra today family health home bless',\n",
       " 'pella v newton process',\n",
       " 'enjoy weird news sunday poll youtube stmetalgod',\n",
       " 'oh think st century start fact start get right cnn people',\n",
       " 'never realize much love someone watch love someone else',\n",
       " 'unexpected unplanned family walk beach dog even sun lush bliss happy xxx',\n",
       " 'cashier panera think wig real',\n",
       " 'pass gas home alone make feel extra',\n",
       " 'constantly rush around conducive zen',\n",
       " 'moment life life september',\n",
       " 'want help make happen dreamscancometrue heart',\n",
       " 'moment life life august',\n",
       " 'yey humpdaypints wednesday boo thursday',\n",
       " 'fuck sure one rainbow throw brick stoptorture closeguantanamo endpsyweapons',\n",
       " 'yes serve need food',\n",
       " 'attention commodity today trust commodity tomorrow uxnext consent ui userexperience',\n",
       " 'ive never see anything matty elise jam blunt performance queen awkward bachelorau',\n",
       " 'u ease attention take tweet like eh u',\n",
       " 'thank followinghappy sunday',\n",
       " 'eng run dream seonghyunwoo iwontgiveup ownrap',\n",
       " 'carrot get eat badger',\n",
       " 'kindness move mountain',\n",
       " 'vhrememberschester feel completely music dedication inspire influence lot stay ripchester',\n",
       " 'want come help shower rub lotion entire body whore',\n",
       " 'person filmoremia wait perform',\n",
       " 'people make mountain molehill like come smh',\n",
       " 'could never real peace revenge thuto',\n",
       " 'morning thank allow see another day',\n",
       " 'almost cced late tweet huth guess know',\n",
       " 'lot thing happen sober bask',\n",
       " 'everyday new journey',\n",
       " 'politician like specific medium outlet ban attend corner auspol',\n",
       " 'sarahhuckabeesanders look eyeball trumptrash',\n",
       " 'girl wanna tell love reality booty love',\n",
       " 'time tweet petty stuff nothing mosque bomb u soil',\n",
       " 'faith hope last forever great love corinthian',\n",
       " 'meet jesus exactly v',\n",
       " 'always nice hear professional compliment awwshucks humble',\n",
       " 'era wtf',\n",
       " 'dress christian nudist camp',\n",
       " 'people think new version ed sheeran perfect beyonce duet',\n",
       " 'like say thank follower make today september',\n",
       " 'get shoot almost dy still x progun nra pocketfullon let nothingwouldhavestopped lasvegasshooting',\n",
       " 'west virginia fail victim',\n",
       " 'icanthavenicethingsbecause enough nice thing four girl love call dad fortunate',\n",
       " 'lose co san jose capital city',\n",
       " 'feel bad go doctor yesterday get prescription med confuse newsgirlproblems',\n",
       " 'pretty',\n",
       " 'issa entire hell',\n",
       " 'need always one talk learn even judgement day',\n",
       " 'go keep bless roll thankful',\n",
       " 'really good place moment happy',\n",
       " 'mean could see fun nigga literally nothing twerking exercise',\n",
       " 'shameless news agency become horrible',\n",
       " 'like fuck happy work',\n",
       " 'drake beyonce portrait studio mayweather mcgregor portrait paint home talkabtit',\n",
       " 'mane game miss lil wayne',\n",
       " 'yellow like second best flavor least double orange',\n",
       " 'crunchy mom dream come true',\n",
       " 'gentrification save parent stone house buck county pa partsunknown',\n",
       " 'close buy lot eurusd pip total today pip',\n",
       " 'love love love voice',\n",
       " 'time sandboxgang try new andouille sausage coney sbg supportsmallstreamers greatfood',\n",
       " 'neb nebraska make touchdown football collegefootball score big',\n",
       " 'saw mythbusters cosplay convention shit',\n",
       " 'fantastic excite playoff love telvin go jag playoff time',\n",
       " 'wind heal peter build',\n",
       " 'good take risk way success wednesdaywisdom likeword',\n",
       " 'get girl cook',\n",
       " 'study god word nfl season',\n",
       " 'rest assure however invoke faithful holy spirit watch faithdream dreamact congress',\n",
       " 'hiac might watch new osw review much wrestle today bet like osw though',\n",
       " 'never give dream match budget check bank account check faith',\n",
       " 'hero model iloseeveryoneloses watch money rootofallevil want smile hurry pay',\n",
       " 'day one new upgrade day one service work',\n",
       " 'yo sex scene',\n",
       " 'hear heartbeat home doppler first time today cool thing ever still week away last loss',\n",
       " 'wish could missinghim needlove',\n",
       " 'work sideburn lol empire',\n",
       " 'weather indecisive week rain sun england',\n",
       " 'standard good fire fake crowd noise bank tomorrow',\n",
       " 'chester bennington suicide oh shit linkin park officially do',\n",
       " 'tweet sad bill sad remember day u head guy fox dog review u',\n",
       " 'cloud nine stop smile sohappy halfmarathoner',\n",
       " 'get replay official glass cmonson really',\n",
       " 'sadly web browser vulnerable poorly engineer software global daily use webdev software developerproblems',\n",
       " 'nothing exceptional excuse_every jesuschristgivestheedgeask',\n",
       " 'think additional option like love',\n",
       " 'fortunately scrape temporary',\n",
       " 'traitor trump inbred offspring toast adios nationaldisgrace',\n",
       " 'omg everyday',\n",
       " 'find sit park watch duck swan therapeutic care world',\n",
       " 'guy happy place',\n",
       " 'eat fast food week lose pound gotta love',\n",
       " 'album everything literally play entire album noskips',\n",
       " 'stone complitly stone something think brave everything change complete arrogant',\n",
       " 'worry revolution u still laugh maga',\n",
       " 'munchines set tv set ppv v key buy check bestofluck fightnight box',\n",
       " 'low rat',\n",
       " 'home mom mother mothersday motivation mama',\n",
       " 'happy goodday standuptobullies nobullying yay',\n",
       " 'new acquaintance sing r kelly song morning even think r kelly maad long time fkdupthemusic',\n",
       " 'hey shannon capelle thank follow',\n",
       " 'come thou long expect jesus advent',\n",
       " 'gameofthrones high husband want discus paul burrell rehab',\n",
       " 'whuut twitch suppose play videogames ugh',\n",
       " 'dog blanket',\n",
       " 'today good day feelgood',\n",
       " 'know man week u',\n",
       " 'play favorite brother',\n",
       " 'would never imagine happy moment life great day everyone',\n",
       " 'family friend',\n",
       " 'hi please play topat',\n",
       " 'orlando bring',\n",
       " 'oh gosh believe girl',\n",
       " 'american scar north korea modern america soft',\n",
       " 'tyytty nyc city africa nwo phone best phone iphone de game read jp india wheel ce asian ba newyork',\n",
       " 'may build house soul spirit dwell pray may come last unshakable faith',\n",
       " 'ciryon beckon agujaceratops baffle erebus sing melancholy strain orkut fancy cake',\n",
       " 'hard work finally notice could cry right ceo suprised wonderful news',\n",
       " 'thank contribution netball suncorpsupernetball',\n",
       " 'shame moral conscience r drown kool aid defend trump bullshite b embarrass resist',\n",
       " 'think goddamn noah ark get isaac anime tiddies preytojesus steelbeams isfake',\n",
       " 'mighty deliverance wicked way change empower world humanity',\n",
       " 'new dawn new president kenyatwaweza',\n",
       " 'love walk happy house son mummy guess get good news pick school council grin happy',\n",
       " 'maybe perfect circle stay hiatus yuck',\n",
       " 'time supporter coyb alwaysablue',\n",
       " 'life battle world arena make win everyday fruitful week',\n",
       " 'anyone else find baby ant lately never experience ugh ihatebugs',\n",
       " 'third time delete sexually attract horse take leave',\n",
       " 'tonight super dope another awesome show wine seller thank universe',\n",
       " 'open member girl',\n",
       " 'great impeach dumptrump thamendmentnow impeach youreajoke',\n",
       " 'point allaccess watch stream',\n",
       " 'smoke joint jump rope min justfitthings',\n",
       " 'slap judge memorial haole parent set chair right front foot id like watch kid play',\n",
       " 'hard walk walk alone also walk make strong',\n",
       " 'well delete account driver customer service slow inefficient byebye hello lyft',\n",
       " 'catalan fundamental righs protect europe useless',\n",
       " 'much thankful year',\n",
       " 'thanksgiving fun familyiseverything',\n",
       " 'last practice tonight jo team leaf sunday train coronado next week come back h season',\n",
       " 'monte grab bbc long sleeve xmas',\n",
       " 'great film jim carrey play grinch merry christmas comoetition x',\n",
       " 'think die depression whatsthepointsadsucidal',\n",
       " 'quite incredible like book sell anthying',\n",
       " 'moment life life august',\n",
       " 'people family introvert like actually interact',\n",
       " 'island surround water big water ocean water embarrass uspresidentalshame',\n",
       " 'tip build credibility share quality info target audience want poor content may well content',\n",
       " 'know think go great event',\n",
       " 'vote yes gop healthcare bill see dontkillus',\n",
       " 'thank ues starbucks supply today liquid strength beyonce halo itsblaring',\n",
       " 'try eyebrow ring low key scar school tomorrow',\n",
       " 'life professional sport check guy lap positivesmurfenergy',\n",
       " 'saw show enough though',\n",
       " 'lord ring love book much film read film',\n",
       " 'every time see picture video lebanon feel like go cry',\n",
       " 'define solution accelerate perfect illusion',\n",
       " 'person say look person christian say look cross',\n",
       " 'anyone follow back fifthtweet',\n",
       " 'need bench remain player forget mean orlando pirate mathambohlanganani',\n",
       " 'ji ne pyar kya wo join kre zakhmi dard shairi melle ge follow send oo',\n",
       " 'bad',\n",
       " 'thrill work oxfordwood recycle direction dev range modernrustic furniture',\n",
       " 'sad truth stupid people insane people know either mean extremely fuck sad',\n",
       " 'fuck amaze love song everything stand',\n",
       " 'u stand clear ground ur journey people get mad shine much thingstheepeesays bossup',\n",
       " 'smooshie miss official statement miss wtf',\n",
       " 'omg semi finalist gate scholarship',\n",
       " 'need laugh watch rerun lastmanstanding mess u cancel show tv rat',\n",
       " 'without get anywhere idolsasa',\n",
       " 'competitive advantage',\n",
       " 'get discount ihop',\n",
       " 'bts amas',\n",
       " 'work make want get absolutely shit face nurse',\n",
       " 'happy everyone',\n",
       " 'grace perfect require',\n",
       " 'dont lack identity know royalty ijustlovewhoivebecome thankyoujesus iamnothingwithoutgod',\n",
       " 'stay onside lfc',\n",
       " 'lord god thank keep u nation pavilion guidance care never fail stay encourage',\n",
       " 'anxiety normal feel fear anyway think struggle reach xxx',\n",
       " 'stop pee first little girl',\n",
       " 'warren harper quit youtube',\n",
       " 'inject vein',\n",
       " 'close sell lot eurusd pip total today pip',\n",
       " 'since act right n post proper pic nice would b charger hemi sedan white grey',\n",
       " 'retweet wait look awe wait eagerly',\n",
       " 'absolutely massive fan aslan wish christy dignam well',\n",
       " 'ask morning demfundraising happen',\n",
       " 'bad think also far love feel',\n",
       " 'book weekend getaway dog last trip baby arrive',\n",
       " 'halloween candy store wtf',\n",
       " 'player lock arm peace solidarity',\n",
       " 'could hear hint accent talk cautiously optimistic soon',\n",
       " 'somehow baby marwake manegi vulgar condomads time smritiirani',\n",
       " 'never rid elevator',\n",
       " 'still king make sure well dress king elevate social content thinkflame',\n",
       " 'good morning beautiful people wonderful day full vibe leave room negativity hr pas beautiful',\n",
       " 'wake morning bark decide meow decide animal want confuse com',\n",
       " 'people call u non creatives around',\n",
       " 'close buy lot eurusd pip total today pip',\n",
       " 'look forward read fear precis give max frisson basically unravel',\n",
       " 'like respectfully decline',\n",
       " 'problem add game time account open ticket response',\n",
       " 'look forward lovely meal late birthdayparty happytimes happysunday',\n",
       " 'aldi open near best news hear aldisnumberfan',\n",
       " 'point nigeria realize development lie political election divine selection arise',\n",
       " 'screw life want food hungry',\n",
       " 'crowd boo gatlin iaafworldchamps',\n",
       " 'never give dream make dream come october pm',\n",
       " 'gonna go ahead pray pay back money steal u',\n",
       " 'total commitment give within opportunity display holiness',\n",
       " 'hey tyler please play thank u htownstopat',\n",
       " 'accomplish great thing must well act',\n",
       " 'era',\n",
       " 'read research study get along become even conscious nwo',\n",
       " 'today new fresh also go hour leadership',\n",
       " 'one hour today one thing patient cost cost family',\n",
       " 'boy good cantclosetheyearbok',\n",
       " 'moment life life december pm',\n",
       " 'really enjoy',\n",
       " 'whokilledgauri bhakts bjp stop blame congress lankeshmurdered do bjp coz expose ur government',\n",
       " 'patriot every country single payer healthcare say great country',\n",
       " 'swell lymph node realize codeine light',\n",
       " 'happen',\n",
       " 'hate get test know im good',\n",
       " 'watch power ranger love movie assemble end',\n",
       " 'remove boot remove jacket remove pant begin weekend happyfriday',\n",
       " 'get catch eat lunch alone car nexttimehidinginthebackseat immybestfriend',\n",
       " 'many people family friend',\n",
       " 'judy',\n",
       " 'bite race kerfuffle',\n",
       " 'serotonin heal vitality gratitude deserve snowboard kite surf',\n",
       " 'man want new note im still scar faulty nope panicattack',\n",
       " 'weird lady one sub keep sink grind didnt access til document grace wolfenstein',\n",
       " 'look forward today game son get turn mascot come county stockportcounty',\n",
       " 'moment life life july pm',\n",
       " 'busy week chill cider cat daysofselfcare cider',\n",
       " 'award show thing past maybe lose generation maybe emmy yxe',\n",
       " 'kinda voodoo king something retweeted tweet last night govolsthough voodoo',\n",
       " 'month swerte na sa twice month',\n",
       " 'back back',\n",
       " 'must killin',\n",
       " 'people significant others social medium account phone wheresdatrust whatdaf highschool',\n",
       " 'oops fall',\n",
       " 'fluffy want hey love taco send tweet reply sad noayparty',\n",
       " 'thank november hey december please good one life',\n",
       " 'universe know time upgrade let go anything serve belief desire expectation beflexible',\n",
       " 'like say thank follower make today october pm',\n",
       " 'ericbolling thug foxnews altright network profit network',\n",
       " 'people die horrible death leave home aur hum hindu muslim ka fark kar rahe hain forget could u shame',\n",
       " 'see someone leaf get motivate succeed leave behind takeforgranted',\n",
       " 'possible love someone never meet person askingforafriend canithappen isitabadthing whatdoyouthink',\n",
       " 'everything good right',\n",
       " 'train leave peterborough edinburgh paul check ticket train give service deserve thank',\n",
       " 'big thank share wonderful positive supporter lucky',\n",
       " 'game barcelona congratulation realmadrid amaze matchrealmadridi love',\n",
       " 'cheese fry vegetarian',\n",
       " 'everyone cross path gift allah cherish gift bad lesson good bless',\n",
       " 'independent favor much regular loyal ppl seem poll taker m carter say',\n",
       " 'work welcome positive environment since switch feelappreciated lovemyjob',\n",
       " 'way gay guy come men similar way straight men come woman get long way go gym eyewitness',\n",
       " 'night amsterdam book holland away back london lash charlton away',\n",
       " 'kinda suck send like three different place get exclusive leia pop force friday iwanther',\n",
       " 'love',\n",
       " 'sorry look terrify',\n",
       " 'saturday feel like sunday livestreamers',\n",
       " 'beautiful sunday happysunday caribbean',\n",
       " 'shoutouts thing finlandia butter coffee pretty much coffee sweet cream creamer',\n",
       " 'reside place laugh every chance get steve harvey mindbody mindset',\n",
       " 'yaaas sweetheart',\n",
       " 'first foremost need control life',\n",
       " 'lawrence wack',\n",
       " 'snapchat wildmia camwhore snapme sexaddict kikgirls',\n",
       " 'dude clap sentence kelli clappin know want',\n",
       " 'moment life life october pm',\n",
       " 'superman raise smallville supergirl grow midvale live largeball',\n",
       " 'gunby world ever need nonviolent message jesus way teach coercive racism sermon',\n",
       " 'happy birthday ramya bless u',\n",
       " 'excellent choice finance partner auto finance send nothing month pastdue notice charge',\n",
       " 'happy without',\n",
       " 'happy week everyone excite march amaze angel sunday go',\n",
       " 'work',\n",
       " 'watch simplerules sing voice lose count many time see still make laugh',\n",
       " 'kate tooday specialfore mejo hisplaneleavestoomorrow soostill pack wtf hisplane',\n",
       " 'yikes repmn',\n",
       " 'thank lord everything',\n",
       " 'doubt see eye man see eye always see god eye',\n",
       " 'happy first day film',\n",
       " 'former player kill thevoice killedit neverstopdreaming wow',\n",
       " 'care kailah cocky contradict si',\n",
       " 'steady pal big chance hoodlum today',\n",
       " 'free shouldof wouldof couldof ifs buts maybes free pressure doubt create mind',\n",
       " 'get job honestly one care brown anymore thingstodo',\n",
       " 'orginal detroit bank acrylic board outdated map detroit area oneofakind',\n",
       " 'especially spiritual power love lie deep inside u love heal',\n",
       " 'bag',\n",
       " 'think couldnt',\n",
       " 'sometimes extremely hard loose st reward tho never loose chance good person love',\n",
       " 'think edit last night show need serious rework love good blindside nothing hint result',\n",
       " 'feel check someone instagram like post mistake',\n",
       " 'ignore really good thing bore friendsneeded',\n",
       " 'heavenly father protect men manchester struggle leave sin alone esp late night send angel human form',\n",
       " 'tuuune remind club planet earth back day day thingscanonlygetbetter',\n",
       " 'relationship equal heart provide',\n",
       " 'always get fire music play',\n",
       " 'remember bill guerin crosby cup marleau matthew leaf optimism',\n",
       " 'devil beat bad entire life glad god call home tire',\n",
       " 'hi nicole set u play tonight watch u live website tomorrowlandlive',\n",
       " 'tire see light skin dude butt big screen',\n",
       " 'grateful work job feel like work',\n",
       " 'oppose date race yet find anyone care enough want learn partake culture wait',\n",
       " 'make social worker break peekaboo',\n",
       " 'happy day glad inspire talented humble guy back field offthepup',\n",
       " 'zbc tell like',\n",
       " 'everything fall place',\n",
       " 'ufff feel travel cloud',\n",
       " 'keep praise god',\n",
       " 'experience experience good bad always learn',\n",
       " 'jv lose tough one new learn grow improve next game pursueexcellence',\n",
       " 'happy sabbath everyone happysabbath',\n",
       " 'mr moseby',\n",
       " 'feel conditional single familytodaywithfunmijohnson',\n",
       " 'time come',\n",
       " 'good morning send way redz',\n",
       " 'someone share netflix account plz real need netflix strangerthings problem people plz help',\n",
       " 'get tire ignorant people run mouth like tell people help anyone else fuckn dandy',\n",
       " 'sooo glad sunday thing lay alter enough toleavethe stress withgod',\n",
       " 'everything time today lmaoo',\n",
       " 'u keep shove n propaganda throat want bullshit fee',\n",
       " 'first murderer conqueror',\n",
       " 'sundaaate',\n",
       " 'use pomodoro technique help stay focus choose one task focus min take min break',\n",
       " 'obviously know tell anything decide wikileaks',\n",
       " 'karpet go',\n",
       " 'issue always emm',\n",
       " 'see global kingdom builder n destiny changer pm uk n nigeria time sunday u',\n",
       " 'kid virgin day age something proud like freak unicorn awesome',\n",
       " 'probably gonna happen',\n",
       " 'hey feralbarncat thank follow help endeavor ur day',\n",
       " 'today think gun shoot sound minute silence bomb spend whole minuet rag scar',\n",
       " 'send size men trainer instead size woman nd time pls refund arrange',\n",
       " 'love others never change kamsa world always creative unleash',\n",
       " 'simon cat cat pusheen kitty cat cat cute',\n",
       " 'get card night',\n",
       " 'mean go super bowl bersin without benji',\n",
       " 'never understand woman talk kind way husband front people disrespectful',\n",
       " 'shit big flush time get rid',\n",
       " 'please tell kid kit wont sleeve sponsor cpfc',\n",
       " 'disappoint customer service receive go paris mon boy go happen',\n",
       " 'see shit like happen around world make appreciate fact even roof head',\n",
       " '',\n",
       " 'guy allow bully show people get gang terrible',\n",
       " 'outdoor party year make sure put canopy tent brand',\n",
       " 'easy vote way enjoy healthcare benefit american',\n",
       " 'hangover look year old toy story quaver big blanket',\n",
       " 'never give dream make dream come september pm',\n",
       " 'time god business playhard staysharp',\n",
       " 'woman horse nothing good',\n",
       " 'realize shop total ppl christmas year break',\n",
       " 'officially survive teen pregnancy',\n",
       " 'day many level',\n",
       " 'check poll',\n",
       " 'lawrence bad time white people lol',\n",
       " 'finish accuse start betray wait get know judy character good summerreading',\n",
       " 'guess mr luke maile save u miguel montero within next hour',\n",
       " 'member canadian force thank weremember bdnmb',\n",
       " 'many time one need raise complaint single issue',\n",
       " 'umm think appropriate talk god use foul language tweet god like ugly',\n",
       " 'goosebump houston htx hometownpride hometown worldseries history',\n",
       " 'comparison thief breesaidit',\n",
       " 'handsome visitor',\n",
       " 'shout put',\n",
       " 'louiselinton know really actually think delete idiotic comment would fix thing internet truecolors',\n",
       " 'close sell lot eurusd pip total today pip',\n",
       " 'mf bitchin text back reply serious convo lame',\n",
       " 'birthday one talented actress generation',\n",
       " 'access account get pre sale code',\n",
       " 'fall like fall crazy',\n",
       " 'jesus teach u always pray staywokerpc jesustaughtus',\n",
       " '',\n",
       " 'nothing today guarantee tomorrow best kind remember',\n",
       " 'want say choose winner white wtf',\n",
       " 'amen take notice',\n",
       " 'love love love',\n",
       " 'defend charlottesville dead fuck wrong notfuckingpresidential',\n",
       " 'facebook work page upload facebookshouteddown h aaahhh',\n",
       " 'order new wash machine last night free delivery deliver morning',\n",
       " 'yet jail juvenile hall psychologist recommend prisoner join follow religion',\n",
       " 'heartbreaking note incredibly dedicate annafaris son especially love',\n",
       " 'masterchef always make hungry food mouthwatering',\n",
       " 'sick tire sick ughhh',\n",
       " 'read nov ot psalm chapter ot proverb chapter nt john chapter',\n",
       " 'badly need interaction account book',\n",
       " 'today tough day thankful amaze people life make worthwhile',\n",
       " 'praise everyday sunday',\n",
       " 'guess cock block lol',\n",
       " 'lovely even weather',\n",
       " 'please want listen song sir please sir title ayomide ade everywhere',\n",
       " 'student finally think instead',\n",
       " 'moment life life december',\n",
       " 'good connect thank follow wish week',\n",
       " 'today load laundry ink spot music book momlifeartlife',\n",
       " 'close sell lot eurusd pip total today pip',\n",
       " 'post midterm feel stress',\n",
       " 'love energy amped invigorate',\n",
       " 'would appear great track record customerservice point one cancel order',\n",
       " 'still tire',\n",
       " 'itsourtime threelions',\n",
       " 'mood thai food',\n",
       " 'thank much fantastic friday',\n",
       " 'realize utilize creatress creative power life within',\n",
       " 'closet full birkins future wife whatamidoingwrong',\n",
       " 'positive action combine positive think result success',\n",
       " 'help measure life standard may shine brightly never disappoint',\n",
       " 'stay calm thing go way time come passion success failure',\n",
       " 'grateful thanksgiving perpetual henry david thoreau',\n",
       " 'love bneil thank brian',\n",
       " 'cannot powerfully without powerful within leadership billionaire black',\n",
       " 'instead condemn gauri murder question protest india murder shame',\n",
       " 'spend hour work photoshop edit get recognition deserve',\n",
       " 'weird vision sophie parent meet joey tom benzo madden date bacheloretteau',\n",
       " 'cool life temporary need get right',\n",
       " 'stick randle crunch time lakeshow',\n",
       " 'game f cking depress let injure night something gbvsmin',\n",
       " 'car evolve build trash can yet',\n",
       " 'book probably favorite yet nywars god work wonder festival',\n",
       " 'get girl insist let save money future support every decision',\n",
       " 'fantastically beautiful',\n",
       " 'turn thepriceisright dude draw u',\n",
       " 'one door close another one open',\n",
       " 'oh forget hashtag instrumental daijoubu ncthemc wowsoaesthetic',\n",
       " 'le money go like le money delay shithole garbage',\n",
       " 'go bike appreciate tip friend cycle',\n",
       " 'quarter lose million free cash flow long continue hitsbusiness',\n",
       " 'last quarter great time ahead',\n",
       " 'never give dream make dream come july',\n",
       " 'people truly rare dont let',\n",
       " 'lucky fuck men actually like woman',\n",
       " 'backwoods nj',\n",
       " 'thats sci cant understand love load',\n",
       " 'throw anything yeezy call fashion u look like u spend check ur sneak forget rest',\n",
       " 'lol brian drama lol astros',\n",
       " 'usually wen walk hav music along session conversationsinmyhead today different amazin convo god bless',\n",
       " 'ah ffs habsy get even fan abuse',\n",
       " 'close buy lot eurusd pip total today pip',\n",
       " 'incomparable know',\n",
       " 'ready amateur',\n",
       " 'awaken appreciate world story may even miraculous imagine read rev elation amazon kindle god alien',\n",
       " 'ill contrary capacity',\n",
       " 'go vintage glamour tomorrow need enjoyable monday feel pretty aka',\n",
       " 'season tough let get tough show',\n",
       " 'thankful day thankful flexibility career job allow work want want',\n",
       " 'good giggle chat masterchef billwithers hear late week',\n",
       " 'apparently riverdale pick get incest craze ew makeitstop',\n",
       " 'get finger cross patientsfirst teamwarrington',\n",
       " 'sponsor leave one one dollar dollar seanwho',\n",
       " 'actually pretty cute fam familychristmas',\n",
       " 'belated birthday pedicure today whynot imworthit hbme',\n",
       " 'make dump accusation root fact description',\n",
       " 'second mythical team selection rookie tapos undefeated champion pa pgbl pba psc rebel rookie',\n",
       " 'obsessively grateful gratefulalways onlyyou wednesday',\n",
       " 'customer service terrible bc people power refuse make change help employee help customer',\n",
       " 'locs get long waist get slim life good',\n",
       " 'never saturate twitter fee scripture post get wrong love god lot keep real',\n",
       " 'picture legend zelda breath turn',\n",
       " 'win lose see mookie betts dustin pedroia tomorrow',\n",
       " 'satan people bread let eat cake huh jesus fee body fee child',\n",
       " 'great birthday',\n",
       " 'damn short end soon start highlight tho tasha tell lawrence much fuckboy',\n",
       " 'roll bedtime tire grumpy little people attitude fill teenager bedtime teenager kid tire earlybed',\n",
       " 'hey l richardson thank follow',\n",
       " 'moment life life august pm',\n",
       " 'enjoy caricature buffoon shameful dotarddon',\n",
       " 'love cover multitude sin jesus win love win jesus reign victorious israel',\n",
       " 'may thing life least best thing life',\n",
       " 'happy bless goodvibesonly',\n",
       " 'trippy weekend love way one',\n",
       " '',\n",
       " 'europe live celebration de rosa de camp rock party usa de miley cyrus etc etc etc siento',\n",
       " 'god send son world condemn world world might save light love joy mercy',\n",
       " 'technically capacity long term memory unlimited possible remember everything ever happen life',\n",
       " 'agelimit debate make police raid actionaid glis shame guess magye anite say come play',\n",
       " 'omfg rofl well turn regret harddrugskill shellfindout',\n",
       " 'love able wake thank god happythursday',\n",
       " 'laugh every time weirdo try texting dming ale thirst month getalife tucsonreallyaintthatsmallweirdo',\n",
       " 'october good thank ready new month growth bless',\n",
       " 'pray victim lasvegas think family everyone endure senseless tragedy',\n",
       " 'like feel like need make appnt people love',\n",
       " 'wish could watch tonight yank rug end last year',\n",
       " 'bran nooo sad think really hard remember thing lannisters excepttyrion ithinkilikehim hasthags',\n",
       " 'remember taco',\n",
       " 'dear mainlanders basic knowledge geography people',\n",
       " 'new basketball jersey still use old logo usnowlv',\n",
       " 'leave everything god hand eventually see god hand everything',\n",
       " 'barca ready neymar transfer',\n",
       " 'son precious',\n",
       " 'think man get hook smh',\n",
       " 'still prepare campaign could add ons already game',\n",
       " 'man hold time think bro',\n",
       " 'opinion montana really change loveisland bitchy truecolours',\n",
       " 'chilli make laundry clean do chill beer crap tv lovely',\n",
       " 'last night stonepelting ganesharrival muslim hamid ansari tell muslim felt uneasy india ansaricontroversy',\n",
       " 'sad turn level money handler lead payment russian',\n",
       " 'god provide physical need support front line worker live remote village myanmar donate',\n",
       " 'love touch walk darkness plato philosophy',\n",
       " 'literally take best nap library butstilltired',\n",
       " 'come back studiocycling lifetime workhardplayhard',\n",
       " 'never give dream make dream come september',\n",
       " 'love content apply volunteer audio deletionist bay area new medium community messageboard',\n",
       " 'coward failure rhetoric create huge divide country failure nazilover',\n",
       " 'want travel bank account afford go stair truestory',\n",
       " 'trump like spoil year old nuclear weapon thank republican give u another crap president',\n",
       " 'shall say unethically near gm prove one advise matter see',\n",
       " 'bless able go job love come home people love success wednesdaywisdom',\n",
       " 'age adaline movienight sad',\n",
       " 'need food helprequired',\n",
       " 'happen thisseemsgoodthough',\n",
       " 'incredible programme never see anything like volcanic scene',\n",
       " 'get right si rather skinny',\n",
       " 'compliment love',\n",
       " 'spare ancient world protect noah righteousness man others bring great flood peter',\n",
       " 'folk get master p house tonight orlando',\n",
       " 'yo beard boy look dash u lot',\n",
       " 'birthday aekkhuen iikpiiaelwhlaaweraa',\n",
       " 'pray pray pray vigorously everyone wonderful planet dangerous time harvey',\n",
       " 'super dear sweet lakshmi',\n",
       " 'walk wire love gonna high firsttweet',\n",
       " 'look takemywife show would amaze banner',\n",
       " 'omg wish cancel sense love show',\n",
       " 'please play',\n",
       " 'get participation trophy child',\n",
       " 'last three get extra fuss',\n",
       " 'thank topnewfollowers',\n",
       " 'kneel discrimination tebow kneel first god',\n",
       " 'jennn sign',\n",
       " 'bless work hand reveal way right accomplish successfully prosperously',\n",
       " 'god answer prayer already make model ambassador underwear line distraction',\n",
       " 'thank another day',\n",
       " 'guess right never one proud',\n",
       " 'glimpse hope like beacon light midst storm anewhope starwars nerd aboveallstaytrue',\n",
       " 'make pizza mess lol binge watch movie crash lol funtimes movienight yummyhomemadepizzas floureverywhere',\n",
       " 'please change vote system paul lose block lose cuz sore loser bb',\n",
       " 'moment life life december',\n",
       " 'happy thanksgiving',\n",
       " 'glad one thing thing',\n",
       " 'gonna lie miss aol instant messenger aim nothing beat custom away message feel crush sign',\n",
       " 'worry',\n",
       " 'programme jump one thing next odd thechildintime',\n",
       " 'yay back',\n",
       " 'well time pack big blue hide head gamrie intense time crru',\n",
       " 'bhrants great ambrose rollins go shazaro come get work together',\n",
       " 'quantity',\n",
       " 'wanna renew rep dope deserve money deserve sign bonus',\n",
       " 'moment life life september pm',\n",
       " 'thank follow honor',\n",
       " 'exhaustion give way rage blog forthcoming time truth',\n",
       " 'kmoos post talk jooyoung senpais hhmm',\n",
       " 'world need common project',\n",
       " 'watch news social medium minute ugh prayforlasvegas',\n",
       " 'god make',\n",
       " 'walk mile find zero coastal access city illegal',\n",
       " 'day report fault resolve',\n",
       " 'birthday sunflower still beautiful',\n",
       " 'think infest spider big spider infest infestation spider notcool notsafe',\n",
       " 'dig new show happy star chrismeloni law order goin hard',\n",
       " 'make wonder drug addiction hawaii escape already paradise',\n",
       " 'hollywood good true pure good man gimmesugar queensugar',\n",
       " 'saturdaymorning good self others',\n",
       " 'fun side keep real sorta lol come improve show mercy prettyplease',\n",
       " 'vote need honor god word god redemption fit someone past order sin restoration',\n",
       " 'want christmas deed piece property name',\n",
       " 'good month come',\n",
       " 'next',\n",
       " 'im honestly stoke see matt hardy feel like vessel almost fully yaaasss',\n",
       " 'need love',\n",
       " 'want mainly content bring read cringey',\n",
       " 'try see thanksgiving food wall homework',\n",
       " 'also take touristy spot',\n",
       " 'check back presence omcru may practice benefit _ _ rockom',\n",
       " 'big loose diva bb bigboss',\n",
       " 'get pay hourly studio build project artist',\n",
       " 'want love',\n",
       " 'get name song dream could share want get nowhere still go proud',\n",
       " 'fear immobilise faith energize destinyfulfilment lifeisagift runyourracewell',\n",
       " 'simple step effective strategy cmo cx growthhacking roi dx',\n",
       " 'right finally document marathon girlfriend go choose school municipality want teacher',\n",
       " 'amaze thank',\n",
       " 'minute nap monday',\n",
       " 'ikeacroydon customerservice gamble make big purchase boycot dontbuy kitchen badcommunication',\n",
       " 'expect healthy love without loyalty trsust respect',\n",
       " 'add snapchat snapchat porn naked girl',\n",
       " 'celebrate studentmidwives nominate soton student midwife month midsoc important celebrate triumph',\n",
       " 'officially october st people time get',\n",
       " 'josh book god law must mouth day night everytime',\n",
       " 'pain struggle thankyoupapagod',\n",
       " 'important money weather please retweet',\n",
       " 'rebuke fear im feel afraid go b c shoot devil want rebuke name',\n",
       " 'tennesseean happy corker say loud see every day please resign',\n",
       " 'encourage parent positive parent take model god love care discipline parent kidmin nextgen',\n",
       " 'song ito ba ang setlist',\n",
       " 'moment connection make possible best friend get job denmark',\n",
       " 'moment life life november pm',\n",
       " 'review griner good grief see bias league',\n",
       " '',\n",
       " 'nooffense jimcarey minime cant stand stupid silly turn theflash take miss wally flavor add show',\n",
       " 'jesus answer say unto elia truly shall first come restore thing matthew',\n",
       " 'retweet obama',\n",
       " 'love every moment',\n",
       " 'believe believe anything tuesdaythoughts',\n",
       " 'thx like enjoy ya day producer life passion grind',\n",
       " 'back bed goodnight stonernation',\n",
       " 'thx brighttalk virtual summit tip contentstrategy collaboration seek facilitator outside development silo',\n",
       " 'long pennsylvania avenue divisive person ever hold office',\n",
       " 'finish mth course therapy depression today incredible life change help go',\n",
       " 'stop fate strive grace',\n",
       " 'death walk ministry die everyday newman renewyourmind labourforyourfreedom',\n",
       " 'saw drive girl pour water coffee cup apparently get one sure coffeeflavouredwater',\n",
       " 'state religion language one nation incredibleindia plurality independencedayindia happyindependenceday',\n",
       " 'another long week grind real',\n",
       " 'want go japan japan life food sushi',\n",
       " 'damm along w u diehard fan brickyard',\n",
       " 'open even come look around meet staff current student creativemedia',\n",
       " 'faith hope last forever great love corinthian',\n",
       " 'surely mean everything lol nation saturday',\n",
       " 'feel thankful trump family member eat thanksgiving mile away speak',\n",
       " 'wallet dad hate',\n",
       " 'await ur combination thala layeveriyeruthu',\n",
       " 'peacemaker r u one something else ministerleerice',\n",
       " 'use flag raise campaign cash taketheknee',\n",
       " 'open morning see lot anger itsalreadytuesday',\n",
       " 'make happen shock everyone',\n",
       " 'nothin know talk',\n",
       " 'never enjoy sunday get tree cook crockpot meal online shop',\n",
       " 'lousy speech pathetic lie idiot make insecure loudmouth little man boy seek attention',\n",
       " 'stream site feel bite imsure',\n",
       " 'men u r king king',\n",
       " 'scaramucci get fire time come nickname scaredamuch',\n",
       " 'bless day everyone wish',\n",
       " 'tooo',\n",
       " 'affection golden pure good paranoid confuse write',\n",
       " 'power love overcome love power world know peace jimi hendrix charlottesville barcelona',\n",
       " 'close buy lot eurusd pip total today pip',\n",
       " 'two dumb fuck control unprofessional lowratings fakenewstrophy',\n",
       " 'thank need',\n",
       " 'pas stay seventeen carat',\n",
       " 'wed make realize still feel',\n",
       " 'clearly write cross forehead',\n",
       " 'grade content mr wheeler',\n",
       " 'happy br school lifelovesme alliswell trusttheuniverse angel',\n",
       " 'best sesh ever tonight',\n",
       " 'leave work early pick mom airport minifamilyreunion',\n",
       " 'life death slow motion even feel bless lewis black',\n",
       " 'wenty ive',\n",
       " 'wow thats sound good',\n",
       " 'take cause classy new line accept drink',\n",
       " 'glad say retweet',\n",
       " 'kind beautiful enjoy weekend lady genop',\n",
       " 'post last pic take pet august pm',\n",
       " 'vertigo entire night frustrate mercy please chronicdizziness chronicillness',\n",
       " 'nothing stateofmind let think control',\n",
       " 'love immortality emily dickinson',\n",
       " 'ever wanna feel bless look bishop sunset',\n",
       " 'shit signal go watch',\n",
       " 'happy birthday aaliyah beautiful love passe good day aaliyah mend i_love_you',\n",
       " 'whole hater',\n",
       " 'hello everyone know alive wow maga',\n",
       " 'love much doubter cower u rise wtrgpsy',\n",
       " 'lo hace ella solita understand great job advocate delve politics',\n",
       " 'min phone adviser thats listen dyslexic customer notunderstanding dylexic virginmedia',\n",
       " 'topic quite',\n",
       " 'bless bless bless',\n",
       " 'dear friend since love u also ought love one another john',\n",
       " 'amarnathyatrisattacked fierce attack salo lashkar toaba u lashkar toaba pakistan suar ki maut mroge',\n",
       " 'update rain wind breezy time time houston harvey still pray believe go spare houston b do',\n",
       " 'season end season w bran nightking time travel gonna watch threescompany rerun life',\n",
       " 'love',\n",
       " 'someone make tinder dog super like',\n",
       " 'tear tear',\n",
       " 'look amaze think disgust magazine paper comment people especially woman wear x',\n",
       " 'aware secret competition smh monkeysee monkeydo',\n",
       " 'marry well',\n",
       " 'saturday night watch documentary fred rise west thisismylifenow',\n",
       " 'minute leave whoeverheis release germany',\n",
       " 'man pray god answer name gameg u tweep z',\n",
       " 'love job grateful year sixth grader bless',\n",
       " 'new currency thing social medium important',\n",
       " 'let negative think ruin day listen positivemusic boost positiveenergy',\n",
       " 'woohoo another volunteer arrive welcome coast volunteer gambia africa changemakers',\n",
       " 'good',\n",
       " 'historic historic acre',\n",
       " 'hate u fanfic emo',\n",
       " 'find classmate dq triplet',\n",
       " 'yes know thank big moment probs gonna pin whatever never do',\n",
       " 'thank follow',\n",
       " 'also audria fine photo billion notification',\n",
       " 'nothing good good night sleep refresh',\n",
       " 'go haircut fell asleep barber chair',\n",
       " 'insane treat vet respect long requirement commander chief wtf',\n",
       " 'pay bill early always end lead check bill pay mean save',\n",
       " 'get feel bite bitter certain senator bail howdarehe',\n",
       " 'u earpers please get wynonnaearp pop sign u pretty amaze justsaying',\n",
       " 'thanksgiving twitter fam',\n",
       " 'make atlanta finish move get call interview tomorrow',\n",
       " 'apple tree niagararocks need vinyl soon',\n",
       " 'doin haveaniceday',\n",
       " 'another load change sure mean well',\n",
       " 'president really good karma world turn back scaramucci',\n",
       " 'tear prayer travel speak lord give u',\n",
       " 'roast seed good healthy also big success w kid parent healthytravel',\n",
       " 'date night dad last night date day mom today',\n",
       " 'put bop good',\n",
       " 'uncle officially sea sydney methodist sinoti even yet haha proud wish',\n",
       " 'congratulation scott niccole maternityinblackandwhite babyneighbors maternityphotos',\n",
       " 'time work',\n",
       " 'hustle bustle life constant strive create stress zap energy let fix',\n",
       " 'make pay tv license worthwhile alone documentary',\n",
       " 'clearly design failure up publicly accessible amp pin plug stupid',\n",
       " 'see walk circumspectly fool wise redeem time day evil ephesian',\n",
       " 'feel',\n",
       " 'beautiful look lingeage whether worldly matter distraction',\n",
       " 'amaze god work life',\n",
       " 'way god love even do say think',\n",
       " 'oh yeah write grant morrison',\n",
       " 'status belt night day raspy baritone wait bring coffee',\n",
       " 'get tix via presale come boston pinch im dream allcaps',\n",
       " 'thank bladderversary comment everyone',\n",
       " 'hold office due heavy rain wait rain stop chennairain bore',\n",
       " 'sweet dream everyone vacation safe ur love one',\n",
       " 'filipina marry another nationality act snobbish arrogant',\n",
       " 'beautiful irresistible',\n",
       " 'tennessee fan rn',\n",
       " 'mondaymotivation bank holiday country',\n",
       " 'talk minute dumb capital letter low case l look font',\n",
       " 'que shit gotta stop pve complete b',\n",
       " 'good morning want see w one',\n",
       " 'truly kenyan country',\n",
       " 'wake say momma hold hand simple cry',\n",
       " 'venus planet finance conjunct jupiter planet optimism continue nov pattern change goptaxplan',\n",
       " 'enemy try talk believe believe foolishness walk faith sight',\n",
       " 'really enjoy two good drama tv thecuckooscalling',\n",
       " 'disappoint people shake gayathiri hand still lie question abt anthaksari biggbosstamil',\n",
       " 'funko pop dream come true thank wait',\n",
       " 'since release plan watch thor movie finally today watch',\n",
       " 'content livingthedream couldntbehappier smilesallday',\n",
       " 'principle discipline feel rap hideous people',\n",
       " 'iiitttsss matchdayyy wooo cannot wait get back vp villapark partofthepride utv',\n",
       " 'bed early ready hr work week money youngandgettingit hustleharder',\n",
       " 'keemstar call fouseytube',\n",
       " 'well apparently john mccain lose spine brain surgery never put country party senator never',\n",
       " 'club',\n",
       " 'dust storm hit lose hole electrical power perkele',\n",
       " 'like ball drain yes drain wallet first financialdomination mistress gift money',\n",
       " 'publix charge return check charge today check cash',\n",
       " 'know get spend rest life hubby best friend literally best feel',\n",
       " 'timothy study show approve god rightly interpret wordoftruth jesuschristis child teach',\n",
       " 'follow',\n",
       " 'make want get morning creativity strength sucess',\n",
       " 'female dm potential love august pm',\n",
       " 'gentleness self control thing law gal',\n",
       " 'focus write right downtime passion write',\n",
       " 'sanctimony thy name trump impeach',\n",
       " 'never adrenaline rush sneak someone crib sneak bf tonight',\n",
       " 'pause hey new guy chanel tip plus idol bro stay cool bro',\n",
       " 'psa clean bathroom first time year life godbless allgrownup',\n",
       " 'still',\n",
       " 'piece shit aca russiasanctions transrightsarehumanrights russiagate',\n",
       " 'god want release flow life flow move orchestrate incredible speed could change instantly',\n",
       " 'open saw crazy mad market btg bittrex exchanger bitcoingold madmarket',\n",
       " 'would like market platform come alive appearance gbm',\n",
       " 'hey yarra range stay like sister',\n",
       " 'hit every single green light marysville yc walmart',\n",
       " 'forget',\n",
       " 'george',\n",
       " 'event amaze good job bro',\n",
       " 'elvis alien kidnap',\n",
       " 'please feel free change name ao con',\n",
       " 'faith withhold conclusion allow arise adyashanti',\n",
       " 'bute thick',\n",
       " 'game rally player every second match worth watch proud u r getng betr nd betr',\n",
       " 'belong trump keep precious daca kid see get reelect',\n",
       " 'boy want bubble give box rice shake happyboy toddler',\n",
       " 'thank much follow fellow patriot',\n",
       " 'moment life life september',\n",
       " 'make laugh time thank god godisgood blessingsonblessings gameofthonesfinale',\n",
       " 'feel get class',\n",
       " 'local cbs day cw pop yet',\n",
       " 'thank retweets see',\n",
       " 'see guy',\n",
       " 'always cop attitude gratitude',\n",
       " 'christian hope earthly importantly eternal reward ss serioussurvivalstrategies',\n",
       " 'close buy lot eurusd pip total today pip',\n",
       " 'one hour workout day excuse',\n",
       " 'fake twitter account',\n",
       " 'dnt need go church every sunday talk god pray everyday man listen',\n",
       " 'world always find way praise way blame always always give world cause blame love',\n",
       " 'today north korea million innocent people threaten u million people might lose healthcare charge',\n",
       " 'motion send pumpkin jail alongside famous raisin impersonate chocolate chip cookie',\n",
       " 'get lot love',\n",
       " 'straight game',\n",
       " 'display ad menu let know watch trailer choose one thing block gameplay unprompted',\n",
       " 'slightly chat driver still think practise script tumbleweed actorslife lols',\n",
       " 'teamraza need renew love show prettyplease',\n",
       " 'sometimes want complain know go help useadanglavplease criticalfocus ala',\n",
       " 'democratic party get white vote presidential election since become party civil right',\n",
       " 'wonder glow hot lip lippie',\n",
       " 'wait havant since train turn even plan destroy refund miss class',\n",
       " 'yes right hugh support',\n",
       " 'finger cross',\n",
       " 'praise lord nation extol people great toward u lord mercy never fail',\n",
       " 'learn celebrate contribute success alive feel awesome',\n",
       " 'say trouble doubt arise heart sundaymorning spiritchat',\n",
       " 'fab geeta love',\n",
       " 'laugh aloud nd brother say u go love',\n",
       " 'oh diiiferent',\n",
       " 'really',\n",
       " 'love people see beckham like omg kid never cry like yea know hesperfect',\n",
       " 'holy shit do deserve influx hot girl tinder',\n",
       " 'officially free',\n",
       " 'aoepodcast host think likely secret changeling folklore fairy voteordie',\n",
       " 'husband open account newbie goodluck',\n",
       " 'pump watch hotel',\n",
       " 'keep head failure head success jerryseinfeld stay humble bereal great sentiment',\n",
       " 'celebrity like greet customer restaurant tell lot character awesome',\n",
       " 'ok ya break become bougie white trash must see tv news guilty pleasure',\n",
       " 'duncan friend could make day foe learnfromstories learnfrompeople racism nz doublerefugeequota',\n",
       " 'disappoint order receive incomplete refund give expect pay postage due mistake poor',\n",
       " 'find today long bff apparently good enough get new friend hang',\n",
       " 'congratulation son',\n",
       " 'move poor man shake fear',\n",
       " 'pretty fast squeakyclean boom',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galve\\AppData\\Local\\Temp\\ipykernel_4328\\3954056427.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_train['clean_text'] = train_clean\n",
      "C:\\Users\\galve\\AppData\\Local\\Temp\\ipykernel_4328\\3954056427.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_test['clean_text'] = test_clean\n"
     ]
    }
   ],
   "source": [
    "tweets_train['clean_text'] = train_clean\n",
    "tweets_test['clean_text'] = test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         confident obedience write know even ask philem...\n",
       "1         trust faith friend someone trust put faith any...\n",
       "2         enough satisfy goal really money materialism m...\n",
       "3                      god wake chase day godsplan godswork\n",
       "4                               tough time turn symbol hope\n",
       "                                ...                        \n",
       "411967      message ye hear begin love one another john kjv\n",
       "411968    lad hath five barley loaf two small fish among...\n",
       "411969    buy last ticket remain show sell mixedfeeling ...\n",
       "411970                       swear hard work go pay one day\n",
       "411971                           card leave idea get parcel\n",
       "Name: clean_text, Length: 411972, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test.clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galve\\AppData\\Local\\Temp\\ipykernel_4328\\1782234018.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_train['len_text'] = len_text\n"
     ]
    }
   ],
   "source": [
    "len_text = []\n",
    "\n",
    "for text in tweets_train.clean_text:\n",
    "    len_tweet = len(text.split())\n",
    "    len_text.append(len_tweet)\n",
    "    \n",
    "tweets_train['len_text'] = len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>len_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people post add snapchat must dehydrate cuz man</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>see trump dangerous freepress around world tru...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "      <td>issa stalk tasha</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "      <td>thx best time tonight story heartbreakingly au...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>still wait supply liscus</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       emotion  \\\n",
       "0  People who post \"add me on #Snapchat\" must be ...  anticipation   \n",
       "1  @brianklaas As we see, Trump is dangerous to #...       sadness   \n",
       "2                Now ISSA is stalking Tasha 😂😂😂 <LH>          fear   \n",
       "3  @RISKshow @TheKevinAllison Thx for the BEST TI...           joy   \n",
       "4       Still waiting on those supplies Liscus. <LH>  anticipation   \n",
       "\n",
       "                                          clean_text  len_text  \n",
       "0    people post add snapchat must dehydrate cuz man         8  \n",
       "1  see trump dangerous freepress around world tru...         8  \n",
       "2                                   issa stalk tasha         3  \n",
       "3  thx best time tonight story heartbreakingly au...         9  \n",
       "4                           still wait supply liscus         4  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galve\\AppData\\Local\\Temp\\ipykernel_4328\\1771897654.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_test['len_text'] = len_text\n"
     ]
    }
   ],
   "source": [
    "len_text = []\n",
    "for text in tweets_test.clean_text:\n",
    "    len_tweet = len(text.split())\n",
    "    len_text.append(len_tweet)\n",
    "tweets_test['len_text'] = len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>len_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confident obedience write know even ask philem...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trust faith friend someone trust put faith any...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>enough satisfy goal really money materialism m...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>god wake chase day godsplan godswork</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tough time turn symbol hope</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion  \\\n",
       "0  Confident of your obedience, I write to you, k...     NaN   \n",
       "1  \"Trust is not the same as faith. A friend is s...     NaN   \n",
       "2  When do you have enough ? When are you satisfi...     NaN   \n",
       "3  God woke you up, now chase the day #GodsPlan #...     NaN   \n",
       "4  In these tough times, who do YOU turn to as yo...     NaN   \n",
       "\n",
       "                                          clean_text  len_text  \n",
       "0  confident obedience write know even ask philem...         8  \n",
       "1  trust faith friend someone trust put faith any...        11  \n",
       "2  enough satisfy goal really money materialism m...         8  \n",
       "3               god wake chase day godsplan godswork         6  \n",
       "4                        tough time turn symbol hope         5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping any tweet that had 0 or 3 or less text after cleaning (Sibject,Verb,Object)\n",
    "tweets_train = tweets_train[tweets_train['len_text'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping any tweet that had 0 or 3 or less text after cleaning (Sibject,Verb,Object)\n",
    "tweets_test = tweets_test[tweets_test['len_text'] > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Cleaining and Tokenization Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_tokens = []\n",
    "\n",
    "for i,txt in enumerate(tweets_train['clean_text'].values):\n",
    "    tokens = bert_tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    lens_tokens.append(len(tokens))\n",
    "tweets_train['len_tokens'] = lens_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>476361</th>\n",
       "      <td>#2017年今の与党に投票してあなたの愛を守れますか？ #2017年今の与党に投票してあなた...</td>\n",
       "      <td>joy</td>\n",
       "      <td>nian jin noyu dang nitou piao shiteanatanoai w...</td>\n",
       "      <td>43</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397669</th>\n",
       "      <td>#加藤シゲアキ誕生祭 #加藤シゲアキ20代最後の日 #加藤シゲアキ #加藤シゲアキ30歳 #...</td>\n",
       "      <td>joy</td>\n",
       "      <td>jia teng shigeakidan sheng ji jia teng shigeak...</td>\n",
       "      <td>42</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693853</th>\n",
       "      <td>#Aqours2ndLIVE  #Aqours #小林愛香 #降旗愛 #高槻かなこ #逢田梨...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>aqoursndlive aqours xiao lin ai xiang jiang qi...</td>\n",
       "      <td>41</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307900</th>\n",
       "      <td>&lt;LH&gt; #스밍 &lt;LH&gt; #워너블 #윤지성 #하성운 #황민현 #옹성우 #김재환 #강...</td>\n",
       "      <td>joy</td>\n",
       "      <td>seuming weoneobeul yunjiseong haseongun hwangm...</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189821</th>\n",
       "      <td>#쿠키런에서_나는_어떤_쿠키 #노츄 #쿠키생일 &lt;LH&gt; JKday #２０２１ #성인...</td>\n",
       "      <td>joy</td>\n",
       "      <td>kukireoneseo_naneun_eoddeon_kuki nocyu kukisae...</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242743</th>\n",
       "      <td>#GENERATIONS &lt;LH&gt; CYCLONE #ライブビューイング  #京成ローザ #...</td>\n",
       "      <td>anger</td>\n",
       "      <td>generation cyclone raibubiyuingu jing cheng ro...</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428673</th>\n",
       "      <td>#Not_all_karmys_opinion #아미_마지막툽_집중해  #ARMY_FO...</td>\n",
       "      <td>joy</td>\n",
       "      <td>not_all_karmys_opinion ami_majimagtub_jibjungh...</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284989</th>\n",
       "      <td>Related Instagram tags for #Love: #purble #bri...</td>\n",
       "      <td>joy</td>\n",
       "      <td>relate instagram tag love purble bride mao zi ...</td>\n",
       "      <td>29</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178837</th>\n",
       "      <td>#デタカ交換 #ジャニーズJr #Mr.KING #Prince #SixTONES #Lo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>detakajiao huan ziyanizujr mr king prince sixt...</td>\n",
       "      <td>21</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391544</th>\n",
       "      <td>#JABHARRYMETSEJAL nly 10dys lft #1 v dnt hv al...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>jabharrymetsejal nly dy lft v dnt hv albm bzz ...</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780506</th>\n",
       "      <td>Younh And Rich WOO &lt;LH&gt; #종현콘서트_INSPIRED #INSPI...</td>\n",
       "      <td>trust</td>\n",
       "      <td>younh rich woo jonghyeonkonseoteu_inspired ins...</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897680</th>\n",
       "      <td>new song (only one you need) ? &lt;LH&gt; #종현콘서트_INS...</td>\n",
       "      <td>trust</td>\n",
       "      <td>new song one need jonghyeonkonseoteu_inspired ...</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660192</th>\n",
       "      <td>featuring shawol 😘 &lt;LH&gt; #종현콘서트_INSPIRED #INSPI...</td>\n",
       "      <td>trust</td>\n",
       "      <td>feature shawol jonghyeonkonseoteu_inspired ins...</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131988</th>\n",
       "      <td>featuring shawol 😍😘  &lt;LH&gt; #종현콘서트_INSPIRED #INS...</td>\n",
       "      <td>trust</td>\n",
       "      <td>feature shawol jonghyeonkonseoteu_inspired ins...</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076889</th>\n",
       "      <td>#Dear #Tweeters_can_any_one_follow_me #idosen'...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>dear tweeters_can_any_one_follow_me idosen t_h...</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197304</th>\n",
       "      <td>@zukkimonn #インスタ #難しい #やろうと思えば #きっとやれる #きっとできる...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>insuta nan shii yaroutosi eba kitsutoyareru ki...</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239936</th>\n",
       "      <td>Young And Rich WOO &lt;LH&gt; #종현콘서트_INSPIRED #INSPI...</td>\n",
       "      <td>trust</td>\n",
       "      <td>young rich woo jonghyeonkonseoteu_inspired ins...</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152667</th>\n",
       "      <td>warm winter (our season) &lt;LH&gt; #종현콘서트_INSPIRED ...</td>\n",
       "      <td>trust</td>\n",
       "      <td>warm winter season jonghyeonkonseoteu_inspired...</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868329</th>\n",
       "      <td>171110 Wanna One | 'Beautiful' MV POSTER &lt;LH&gt; ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>wanna one beautiful mv poster gangdaniel bagji...</td>\n",
       "      <td>17</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933991</th>\n",
       "      <td>Crazy (Guilty Pleasure) &lt;LH&gt; #종현콘서트_INSPIRED #...</td>\n",
       "      <td>trust</td>\n",
       "      <td>crazy guilty pleasure jonghyeonkonseoteu_inspi...</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575572</th>\n",
       "      <td>Wrt, Japanese on Twitter. It's a little viral ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>wrt japanese twitter little viral due small wo...</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523922</th>\n",
       "      <td>new song? &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비...</td>\n",
       "      <td>trust</td>\n",
       "      <td>new song jonghyeonkonseoteu_inspired inspired_...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915789</th>\n",
       "      <td>Beautiful Tonight &lt;LH&gt; #종현콘서트_INSPIRED #INSPIR...</td>\n",
       "      <td>trust</td>\n",
       "      <td>beautiful tonight jonghyeonkonseoteu_inspired ...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10223</th>\n",
       "      <td>Happy Birthday &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_...</td>\n",
       "      <td>trust</td>\n",
       "      <td>happy birthday jonghyeonkonseoteu_inspired ins...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994386</th>\n",
       "      <td>LoveBelt &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...</td>\n",
       "      <td>trust</td>\n",
       "      <td>lovebelt jonghyeonkonseoteu_inspired inspired_...</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325707</th>\n",
       "      <td>I'm so tired 😔#NewZealandGPG #정세운데뷔축하해 #taeyeo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>tire newzealandgpg jeongseundebwicughahae taey...</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449911</th>\n",
       "      <td>new song again? &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED...</td>\n",
       "      <td>trust</td>\n",
       "      <td>new song jonghyeonkonseoteu_inspired inspired_...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291185</th>\n",
       "      <td>#こぼれる声を #聴かせて #あなたとハネムーン #祝福してる #世界中がエキストラ #永遠...</td>\n",
       "      <td>joy</td>\n",
       "      <td>koborerusheng wo ting kasete anatatohanemun zh...</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625369</th>\n",
       "      <td>Love Belt &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비...</td>\n",
       "      <td>trust</td>\n",
       "      <td>love belt jonghyeonkonseoteu_inspired inspired...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151620</th>\n",
       "      <td>Love Is So Nice &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED...</td>\n",
       "      <td>trust</td>\n",
       "      <td>love nice jonghyeonkonseoteu_inspired inspired...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861248</th>\n",
       "      <td>END OF A DAY &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수...</td>\n",
       "      <td>trust</td>\n",
       "      <td>end day jonghyeonkonseoteu_inspired inspired_b...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696209</th>\n",
       "      <td>Like You &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...</td>\n",
       "      <td>trust</td>\n",
       "      <td>like jonghyeonkonseoteu_inspired inspired_bags...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873662</th>\n",
       "      <td>Cocktail &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...</td>\n",
       "      <td>trust</td>\n",
       "      <td>cocktail jonghyeonkonseoteu_inspired inspired_...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32620</th>\n",
       "      <td>Inspiration &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠...</td>\n",
       "      <td>trust</td>\n",
       "      <td>inspiration jonghyeonkonseoteu_inspired inspir...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512496</th>\n",
       "      <td>NEON &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나 #...</td>\n",
       "      <td>trust</td>\n",
       "      <td>neon jonghyeonkonseoteu_inspired inspired_bags...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488192</th>\n",
       "      <td>LONELY &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나...</td>\n",
       "      <td>trust</td>\n",
       "      <td>lonely jonghyeonkonseoteu_inspired inspired_ba...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320504</th>\n",
       "      <td>Moon &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나 #...</td>\n",
       "      <td>trust</td>\n",
       "      <td>moon jonghyeonkonseoteu_inspired inspired_bags...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495780</th>\n",
       "      <td>Dress Up &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...</td>\n",
       "      <td>trust</td>\n",
       "      <td>dress jonghyeonkonseoteu_inspired inspired_bag...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85864</th>\n",
       "      <td>Let Me Out &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준...</td>\n",
       "      <td>trust</td>\n",
       "      <td>let jonghyeonkonseoteu_inspired inspired_bagsu...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305260</th>\n",
       "      <td>Orbit &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나 ...</td>\n",
       "      <td>trust</td>\n",
       "      <td>orbit jonghyeonkonseoteu_inspired inspired_bag...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666926</th>\n",
       "      <td>#GirIs' TaIk #もう一度~one more time~ #0~ZERO #Lov...</td>\n",
       "      <td>joy</td>\n",
       "      <td>giris taik mouyi du one time zero love hate do...</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960374</th>\n",
       "      <td>No more sad songs!#하프밀리언 #1YearInBLACKPINKsAre...</td>\n",
       "      <td>joy</td>\n",
       "      <td>sad song hapeumilrieon yearinblackpinksarea th...</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166270</th>\n",
       "      <td>E_mhotep DRKYSELA sprague_paul spnn52n9 articl...</td>\n",
       "      <td>joy</td>\n",
       "      <td>e_mhotep drkysela sprague_paul spnnn articles_...</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244865</th>\n",
       "      <td>&lt;LH&gt; #Wishes for all #Womens in #SaudiArabia #...</td>\n",
       "      <td>trust</td>\n",
       "      <td>wish woman saudiarabia drive well mbrwk_lns_lw...</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795284</th>\n",
       "      <td>SHE IS &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나...</td>\n",
       "      <td>trust</td>\n",
       "      <td>jonghyeonkonseoteu_inspired inspired_bagsucilj...</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176670</th>\n",
       "      <td>ONGNIEL IS PERFECT !! &lt;LH&gt; &lt;LH&gt; &lt;LH&gt; &lt;LH&gt; #강다니...</td>\n",
       "      <td>joy</td>\n",
       "      <td>ongniel perfect gangdaniel ongseongu hwangminh...</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72308</th>\n",
       "      <td>what happen to wanna one's make up ? &lt;LH&gt; &lt;LH&gt;...</td>\n",
       "      <td>joy</td>\n",
       "      <td>happen wanna one make gangdaniel ongseongu hwa...</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902000</th>\n",
       "      <td>&lt;LH&gt; #IHaveADream #IStillHaveADream #ImplicitB...</td>\n",
       "      <td>trust</td>\n",
       "      <td>ihaveadream istillhaveadream implicitbiasremov...</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311936</th>\n",
       "      <td>#Blind=#DontBelieve$Dies #Deaf=#DontBelieveGod...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>blind dontbelievedies deaf dontbelievegodspeak...</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244504</th>\n",
       "      <td>#NewShairy #Best_Shairy #Dukhi_Shairy #Nice_Sh...</td>\n",
       "      <td>joy</td>\n",
       "      <td>newshairy best_shairy dukhi_shairy nice_shairy...</td>\n",
       "      <td>14</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text       emotion  \\\n",
       "476361   #2017年今の与党に投票してあなたの愛を守れますか？ #2017年今の与党に投票してあなた...           joy   \n",
       "397669   #加藤シゲアキ誕生祭 #加藤シゲアキ20代最後の日 #加藤シゲアキ #加藤シゲアキ30歳 #...           joy   \n",
       "693853   #Aqours2ndLIVE  #Aqours #小林愛香 #降旗愛 #高槻かなこ #逢田梨...       sadness   \n",
       "307900   <LH> #스밍 <LH> #워너블 #윤지성 #하성운 #황민현 #옹성우 #김재환 #강...           joy   \n",
       "1189821  #쿠키런에서_나는_어떤_쿠키 #노츄 #쿠키생일 <LH> JKday #２０２１ #성인...           joy   \n",
       "1242743  #GENERATIONS <LH> CYCLONE #ライブビューイング  #京成ローザ #...         anger   \n",
       "428673   #Not_all_karmys_opinion #아미_마지막툽_집중해  #ARMY_FO...           joy   \n",
       "284989   Related Instagram tags for #Love: #purble #bri...           joy   \n",
       "178837   #デタカ交換 #ジャニーズJr #Mr.KING #Prince #SixTONES #Lo...           joy   \n",
       "1391544  #JABHARRYMETSEJAL nly 10dys lft #1 v dnt hv al...       sadness   \n",
       "780506   Younh And Rich WOO <LH> #종현콘서트_INSPIRED #INSPI...         trust   \n",
       "897680   new song (only one you need) ? <LH> #종현콘서트_INS...         trust   \n",
       "660192   featuring shawol 😘 <LH> #종현콘서트_INSPIRED #INSPI...         trust   \n",
       "131988   featuring shawol 😍😘  <LH> #종현콘서트_INSPIRED #INS...         trust   \n",
       "1076889  #Dear #Tweeters_can_any_one_follow_me #idosen'...  anticipation   \n",
       "1197304  @zukkimonn #インスタ #難しい #やろうと思えば #きっとやれる #きっとできる...  anticipation   \n",
       "1239936  Young And Rich WOO <LH> #종현콘서트_INSPIRED #INSPI...         trust   \n",
       "152667   warm winter (our season) <LH> #종현콘서트_INSPIRED ...         trust   \n",
       "868329   171110 Wanna One | 'Beautiful' MV POSTER <LH> ...           joy   \n",
       "933991   Crazy (Guilty Pleasure) <LH> #종현콘서트_INSPIRED #...         trust   \n",
       "575572   Wrt, Japanese on Twitter. It's a little viral ...           joy   \n",
       "523922   new song? <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비...         trust   \n",
       "915789   Beautiful Tonight <LH> #종현콘서트_INSPIRED #INSPIR...         trust   \n",
       "10223    Happy Birthday <LH> #종현콘서트_INSPIRED #INSPIRED_...         trust   \n",
       "994386   LoveBelt <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...         trust   \n",
       "1325707  I'm so tired 😔#NewZealandGPG #정세운데뷔축하해 #taeyeo...           joy   \n",
       "449911   new song again? <LH> #종현콘서트_INSPIRED #INSPIRED...         trust   \n",
       "291185   #こぼれる声を #聴かせて #あなたとハネムーン #祝福してる #世界中がエキストラ #永遠...           joy   \n",
       "625369   Love Belt <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비...         trust   \n",
       "151620   Love Is So Nice <LH> #종현콘서트_INSPIRED #INSPIRED...         trust   \n",
       "861248   END OF A DAY <LH> #종현콘서트_INSPIRED #INSPIRED_박수...         trust   \n",
       "696209   Like You <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...         trust   \n",
       "873662   Cocktail <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...         trust   \n",
       "32620    Inspiration <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠...         trust   \n",
       "512496   NEON <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나 #...         trust   \n",
       "488192   LONELY <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나...         trust   \n",
       "320504   Moon <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나 #...         trust   \n",
       "495780   Dress Up <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...         trust   \n",
       "85864    Let Me Out <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준...         trust   \n",
       "1305260  Orbit <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나 ...         trust   \n",
       "666926   #GirIs' TaIk #もう一度~one more time~ #0~ZERO #Lov...           joy   \n",
       "960374   No more sad songs!#하프밀리언 #1YearInBLACKPINKsAre...           joy   \n",
       "166270   E_mhotep DRKYSELA sprague_paul spnn52n9 articl...           joy   \n",
       "244865   <LH> #Wishes for all #Womens in #SaudiArabia #...         trust   \n",
       "795284   SHE IS <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되셨나...         trust   \n",
       "176670   ONGNIEL IS PERFECT !! <LH> <LH> <LH> <LH> #강다니...           joy   \n",
       "72308    what happen to wanna one's make up ? <LH> <LH>...           joy   \n",
       "902000   <LH> #IHaveADream #IStillHaveADream #ImplicitB...         trust   \n",
       "1311936  #Blind=#DontBelieve$Dies #Deaf=#DontBelieveGod...       disgust   \n",
       "244504   #NewShairy #Best_Shairy #Dukhi_Shairy #Nice_Sh...           joy   \n",
       "\n",
       "                                                clean_text  len_text  \\\n",
       "476361   nian jin noyu dang nitou piao shiteanatanoai w...        43   \n",
       "397669   jia teng shigeakidan sheng ji jia teng shigeak...        42   \n",
       "693853   aqoursndlive aqours xiao lin ai xiang jiang qi...        41   \n",
       "307900   seuming weoneobeul yunjiseong haseongun hwangm...        19   \n",
       "1189821  kukireoneseo_naneun_eoddeon_kuki nocyu kukisae...        11   \n",
       "1242743  generation cyclone raibubiyuingu jing cheng ro...        38   \n",
       "428673   not_all_karmys_opinion ami_majimagtub_jibjungh...         7   \n",
       "284989   relate instagram tag love purble bride mao zi ...        29   \n",
       "178837   detakajiao huan ziyanizujr mr king prince sixt...        21   \n",
       "1391544  jabharrymetsejal nly dy lft v dnt hv albm bzz ...        22   \n",
       "780506   younh rich woo jonghyeonkonseoteu_inspired ins...        10   \n",
       "897680   new song one need jonghyeonkonseoteu_inspired ...        11   \n",
       "660192   feature shawol jonghyeonkonseoteu_inspired ins...         9   \n",
       "131988   feature shawol jonghyeonkonseoteu_inspired ins...         9   \n",
       "1076889  dear tweeters_can_any_one_follow_me idosen t_h...         6   \n",
       "1197304  insuta nan shii yaroutosi eba kitsutoyareru ki...        15   \n",
       "1239936  young rich woo jonghyeonkonseoteu_inspired ins...        10   \n",
       "152667   warm winter season jonghyeonkonseoteu_inspired...        10   \n",
       "868329   wanna one beautiful mv poster gangdaniel bagji...        17   \n",
       "933991   crazy guilty pleasure jonghyeonkonseoteu_inspi...        10   \n",
       "575572   wrt japanese twitter little viral due small wo...        25   \n",
       "523922   new song jonghyeonkonseoteu_inspired inspired_...         9   \n",
       "915789   beautiful tonight jonghyeonkonseoteu_inspired ...         9   \n",
       "10223    happy birthday jonghyeonkonseoteu_inspired ins...         9   \n",
       "994386   lovebelt jonghyeonkonseoteu_inspired inspired_...         8   \n",
       "1325707  tire newzealandgpg jeongseundebwicughahae taey...        12   \n",
       "449911   new song jonghyeonkonseoteu_inspired inspired_...         9   \n",
       "291185   koborerusheng wo ting kasete anatatohanemun zh...        24   \n",
       "625369   love belt jonghyeonkonseoteu_inspired inspired...         9   \n",
       "151620   love nice jonghyeonkonseoteu_inspired inspired...         9   \n",
       "861248   end day jonghyeonkonseoteu_inspired inspired_b...         9   \n",
       "696209   like jonghyeonkonseoteu_inspired inspired_bags...         8   \n",
       "873662   cocktail jonghyeonkonseoteu_inspired inspired_...         8   \n",
       "32620    inspiration jonghyeonkonseoteu_inspired inspir...         8   \n",
       "512496   neon jonghyeonkonseoteu_inspired inspired_bags...         8   \n",
       "488192   lonely jonghyeonkonseoteu_inspired inspired_ba...         8   \n",
       "320504   moon jonghyeonkonseoteu_inspired inspired_bags...         8   \n",
       "495780   dress jonghyeonkonseoteu_inspired inspired_bag...         8   \n",
       "85864    let jonghyeonkonseoteu_inspired inspired_bagsu...         8   \n",
       "1305260  orbit jonghyeonkonseoteu_inspired inspired_bag...         8   \n",
       "666926   giris taik mouyi du one time zero love hate do...        26   \n",
       "960374   sad song hapeumilrieon yearinblackpinksarea th...        12   \n",
       "166270   e_mhotep drkysela sprague_paul spnnn articles_...        13   \n",
       "244865   wish woman saudiarabia drive well mbrwk_lns_lw...         8   \n",
       "795284   jonghyeonkonseoteu_inspired inspired_bagsucilj...         7   \n",
       "176670   ongniel perfect gangdaniel ongseongu hwangminh...        13   \n",
       "72308    happen wanna one make gangdaniel ongseongu hwa...        15   \n",
       "902000   ihaveadream istillhaveadream implicitbiasremov...         9   \n",
       "1311936  blind dontbelievedies deaf dontbelievegodspeak...        10   \n",
       "244504   newshairy best_shairy dukhi_shairy nice_shairy...        14   \n",
       "\n",
       "         len_tokens  \n",
       "476361           94  \n",
       "397669           80  \n",
       "693853           70  \n",
       "307900           68  \n",
       "1189821          59  \n",
       "1242743          58  \n",
       "428673           58  \n",
       "284989           55  \n",
       "178837           54  \n",
       "1391544          52  \n",
       "780506           52  \n",
       "897680           52  \n",
       "660192           51  \n",
       "131988           51  \n",
       "1076889          51  \n",
       "1197304          51  \n",
       "1239936          51  \n",
       "152667           51  \n",
       "868329           51  \n",
       "933991           51  \n",
       "575572           51  \n",
       "523922           50  \n",
       "915789           50  \n",
       "10223            50  \n",
       "994386           50  \n",
       "1325707          50  \n",
       "449911           50  \n",
       "291185           50  \n",
       "625369           50  \n",
       "151620           50  \n",
       "861248           50  \n",
       "696209           49  \n",
       "873662           49  \n",
       "32620            49  \n",
       "512496           49  \n",
       "488192           49  \n",
       "320504           49  \n",
       "495780           49  \n",
       "85864            49  \n",
       "1305260          49  \n",
       "666926           49  \n",
       "960374           48  \n",
       "166270           48  \n",
       "244865           48  \n",
       "795284           48  \n",
       "176670           47  \n",
       "72308            47  \n",
       "902000           47  \n",
       "1311936          47  \n",
       "244504           47  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train = tweets_train.sort_values(by='len_tokens', ascending=False)\n",
    "tweets_train.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>523922</th>\n",
       "      <td>new song? &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비...</td>\n",
       "      <td>trust</td>\n",
       "      <td>new song jonghyeonkonseoteu_inspired inspired_...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915789</th>\n",
       "      <td>Beautiful Tonight &lt;LH&gt; #종현콘서트_INSPIRED #INSPIR...</td>\n",
       "      <td>trust</td>\n",
       "      <td>beautiful tonight jonghyeonkonseoteu_inspired ...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10223</th>\n",
       "      <td>Happy Birthday &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_...</td>\n",
       "      <td>trust</td>\n",
       "      <td>happy birthday jonghyeonkonseoteu_inspired ins...</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994386</th>\n",
       "      <td>LoveBelt &lt;LH&gt; #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...</td>\n",
       "      <td>trust</td>\n",
       "      <td>lovebelt jonghyeonkonseoteu_inspired inspired_...</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325707</th>\n",
       "      <td>I'm so tired 😔#NewZealandGPG #정세운데뷔축하해 #taeyeo...</td>\n",
       "      <td>joy</td>\n",
       "      <td>tire newzealandgpg jeongseundebwicughahae taey...</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text emotion  \\\n",
       "523922   new song? <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비...   trust   \n",
       "915789   Beautiful Tonight <LH> #종현콘서트_INSPIRED #INSPIR...   trust   \n",
       "10223    Happy Birthday <LH> #종현콘서트_INSPIRED #INSPIRED_...   trust   \n",
       "994386   LoveBelt <LH> #종현콘서트_INSPIRED #INSPIRED_박수칠준비되...   trust   \n",
       "1325707  I'm so tired 😔#NewZealandGPG #정세운데뷔축하해 #taeyeo...     joy   \n",
       "\n",
       "                                                clean_text  len_text  \\\n",
       "523922   new song jonghyeonkonseoteu_inspired inspired_...         9   \n",
       "915789   beautiful tonight jonghyeonkonseoteu_inspired ...         9   \n",
       "10223    happy birthday jonghyeonkonseoteu_inspired ins...         9   \n",
       "994386   lovebelt jonghyeonkonseoteu_inspired inspired_...         8   \n",
       "1325707  tire newzealandgpg jeongseundebwicughahae taey...        12   \n",
       "\n",
       "         len_tokens  \n",
       "523922           50  \n",
       "915789           50  \n",
       "10223            50  \n",
       "994386           50  \n",
       "1325707          50  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of any excessive tokenization tweet\n",
    "tweets_train = tweets_train[tweets_train['len_tokens'] <= 50]\n",
    "tweets_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshuffle and Reset index\n",
    "tweets_train = tweets_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_tokens = []\n",
    "\n",
    "for i,txt in enumerate(tweets_test['clean_text'].values):\n",
    "    tokens = bert_tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    lens_tokens.append(len(tokens))\n",
    "tweets_test['len_tokens'] = lens_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81415</th>\n",
       "      <td>#صباحات_النصر  pin5912DC0D #سكس_كتابي #المدينة...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sbht_lnsr pindcd sks_ktby lmdyn k mhnh nyk zb ...</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399380</th>\n",
       "      <td>How @parcelforce hv faild ths wk: Tues drvr cl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hv faild th wk tues drvr cldnt use drbll ystrd...</td>\n",
       "      <td>21</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356504</th>\n",
       "      <td>@MSNBC Hee haz kno respekt cuz hee didnnt nock...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hee haz kno respekt cuz hee didnnt nock owt mi...</td>\n",
       "      <td>21</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148629</th>\n",
       "      <td>2 cmpltly #TrustInALLAH z 2 b lyk a child who ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cmpltly trustinallah z b lyk child knz dply dt...</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314812</th>\n",
       "      <td>@OfficeOfRG hw cm u cl ppl of GJ Gundas; let m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hw cm u cl ppl gj gundas let ask u hw u go gj ...</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186270</th>\n",
       "      <td>At da height of 13K fts, VIPs of eithr cydr wr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da height k ft vip eithr cydr wre gv spcial pe...</td>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357690</th>\n",
       "      <td>Colossians1:27 2whomGODwouldMAKEknownWHAT ISth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>colossian whomgodwouldmakeknownwhat istheriche...</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407805</th>\n",
       "      <td>#SiezePaddocksAssets  #SiezePaddocksAssets  #S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>siezepaddocksassets siezepaddocksassets siezep...</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367835</th>\n",
       "      <td>#DontEndKRPKAB #KRPKABians Were Busy Seeing #I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dontendkrpkab krpkabians busy see ishqbaaz bt ...</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41912</th>\n",
       "      <td>MoreFAKEnews is generated &amp; pushed by FOX NEWs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morefakenews generate push fox news d_trump tr...</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265153</th>\n",
       "      <td>Gurmt ramrahim sentncd to 10yrs in jail fr rap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gurmt ramrahim sentncd yr jail fr rape im real...</td>\n",
       "      <td>17</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357266</th>\n",
       "      <td>#GodAndPills #TestTheSpirit #IAlwaysKnewThereW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>godandpills testthespirit ialwaysknewtherewasa...</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410022</th>\n",
       "      <td>ihasjohn_bob ELMO! NOOOO! Haha thanks John Bob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ihasjohn_bob elmo nooo haha thank john bob hum...</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193963</th>\n",
       "      <td>Wsh u all Hppy Anant Chaturdashi.Pray To God F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wsh u hppy anant chaturdashi pray god fr ur pr...</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182462</th>\n",
       "      <td>#MONSTA_X  170722  Beautiful jap ver MV teaser...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>monsta_x beautiful jap v mv teaser monseutaegs...</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166434</th>\n",
       "      <td>K3G : Multistarrer OSO : Multistarrer CE : Bco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kg multistarrer oso multistarrer ce bcoz dp ro...</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286018</th>\n",
       "      <td>Mets lineup vs. DBacks:   Nimmo CF Cabrera 2B ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mets lineup v dbacks nimmo cf cabrera b confor...</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309636</th>\n",
       "      <td>I fucking love crepes ❤️❤️❤️❤️ #crepes#itslit ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fuck love crepe crepesitslit crepesarelife abu...</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182416</th>\n",
       "      <td>@capt_amarinder Sir, Punjab ch #electricity de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sir punjab ch electricity de problm da v kuch ...</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11062</th>\n",
       "      <td>Haha pukhtoon ?? Pukhtoon are nt lyk ths bibi ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>haha pukhtoon pukhtoon nt lyk th bibi u prtctv...</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text emotion  \\\n",
       "81415   #صباحات_النصر  pin5912DC0D #سكس_كتابي #المدينة...     NaN   \n",
       "399380  How @parcelforce hv faild ths wk: Tues drvr cl...     NaN   \n",
       "356504  @MSNBC Hee haz kno respekt cuz hee didnnt nock...     NaN   \n",
       "148629  2 cmpltly #TrustInALLAH z 2 b lyk a child who ...     NaN   \n",
       "314812  @OfficeOfRG hw cm u cl ppl of GJ Gundas; let m...     NaN   \n",
       "186270  At da height of 13K fts, VIPs of eithr cydr wr...     NaN   \n",
       "357690  Colossians1:27 2whomGODwouldMAKEknownWHAT ISth...     NaN   \n",
       "407805  #SiezePaddocksAssets  #SiezePaddocksAssets  #S...     NaN   \n",
       "367835  #DontEndKRPKAB #KRPKABians Were Busy Seeing #I...     NaN   \n",
       "41912   MoreFAKEnews is generated & pushed by FOX NEWs...     NaN   \n",
       "265153  Gurmt ramrahim sentncd to 10yrs in jail fr rap...     NaN   \n",
       "357266  #GodAndPills #TestTheSpirit #IAlwaysKnewThereW...     NaN   \n",
       "410022  ihasjohn_bob ELMO! NOOOO! Haha thanks John Bob...     NaN   \n",
       "193963  Wsh u all Hppy Anant Chaturdashi.Pray To God F...     NaN   \n",
       "182462  #MONSTA_X  170722  Beautiful jap ver MV teaser...     NaN   \n",
       "166434  K3G : Multistarrer OSO : Multistarrer CE : Bco...     NaN   \n",
       "286018  Mets lineup vs. DBacks:   Nimmo CF Cabrera 2B ...     NaN   \n",
       "309636  I fucking love crepes ❤️❤️❤️❤️ #crepes#itslit ...     NaN   \n",
       "182416  @capt_amarinder Sir, Punjab ch #electricity de...     NaN   \n",
       "11062   Haha pukhtoon ?? Pukhtoon are nt lyk ths bibi ...     NaN   \n",
       "\n",
       "                                               clean_text  len_text  \\\n",
       "81415   sbht_lnsr pindcd sks_ktby lmdyn k mhnh nyk zb ...        21   \n",
       "399380  hv faild th wk tues drvr cldnt use drbll ystrd...        21   \n",
       "356504  hee haz kno respekt cuz hee didnnt nock owt mi...        21   \n",
       "148629  cmpltly trustinallah z b lyk child knz dply dt...        24   \n",
       "314812  hw cm u cl ppl gj gundas let ask u hw u go gj ...        26   \n",
       "186270  da height k ft vip eithr cydr wre gv spcial pe...        21   \n",
       "357690  colossian whomgodwouldmakeknownwhat istheriche...         9   \n",
       "407805  siezepaddocksassets siezepaddocksassets siezep...         6   \n",
       "367835  dontendkrpkab krpkabians busy see ishqbaaz bt ...        14   \n",
       "41912   morefakenews generate push fox news d_trump tr...        10   \n",
       "265153  gurmt ramrahim sentncd yr jail fr rape im real...        17   \n",
       "357266  godandpills testthespirit ialwaysknewtherewasa...        10   \n",
       "410022  ihasjohn_bob elmo nooo haha thank john bob hum...        16   \n",
       "193963  wsh u hppy anant chaturdashi pray god fr ur pr...        23   \n",
       "182462  monsta_x beautiful jap v mv teaser monseutaegs...        16   \n",
       "166434  kg multistarrer oso multistarrer ce bcoz dp ro...        20   \n",
       "286018  mets lineup v dbacks nimmo cf cabrera b confor...        22   \n",
       "309636  fuck love crepe crepesitslit crepesarelife abu...         8   \n",
       "182416  sir punjab ch electricity de problm da v kuch ...        18   \n",
       "11062   haha pukhtoon pukhtoon nt lyk th bibi u prtctv...        17   \n",
       "\n",
       "        len_tokens  \n",
       "81415           58  \n",
       "399380          47  \n",
       "356504          45  \n",
       "148629          45  \n",
       "314812          44  \n",
       "186270          43  \n",
       "357690          43  \n",
       "407805          43  \n",
       "367835          42  \n",
       "41912           41  \n",
       "265153          41  \n",
       "357266          40  \n",
       "410022          40  \n",
       "193963          40  \n",
       "182462          40  \n",
       "166434          39  \n",
       "286018          39  \n",
       "309636          39  \n",
       "182416          39  \n",
       "11062           39  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test = tweets_test.sort_values(by='len_tokens', ascending=False)\n",
    "tweets_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410022</th>\n",
       "      <td>ihasjohn_bob ELMO! NOOOO! Haha thanks John Bob...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ihasjohn_bob elmo nooo haha thank john bob hum...</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193963</th>\n",
       "      <td>Wsh u all Hppy Anant Chaturdashi.Pray To God F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wsh u hppy anant chaturdashi pray god fr ur pr...</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182462</th>\n",
       "      <td>#MONSTA_X  170722  Beautiful jap ver MV teaser...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>monsta_x beautiful jap v mv teaser monseutaegs...</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166434</th>\n",
       "      <td>K3G : Multistarrer OSO : Multistarrer CE : Bco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kg multistarrer oso multistarrer ce bcoz dp ro...</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286018</th>\n",
       "      <td>Mets lineup vs. DBacks:   Nimmo CF Cabrera 2B ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mets lineup v dbacks nimmo cf cabrera b confor...</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text emotion  \\\n",
       "410022  ihasjohn_bob ELMO! NOOOO! Haha thanks John Bob...     NaN   \n",
       "193963  Wsh u all Hppy Anant Chaturdashi.Pray To God F...     NaN   \n",
       "182462  #MONSTA_X  170722  Beautiful jap ver MV teaser...     NaN   \n",
       "166434  K3G : Multistarrer OSO : Multistarrer CE : Bco...     NaN   \n",
       "286018  Mets lineup vs. DBacks:   Nimmo CF Cabrera 2B ...     NaN   \n",
       "\n",
       "                                               clean_text  len_text  \\\n",
       "410022  ihasjohn_bob elmo nooo haha thank john bob hum...        16   \n",
       "193963  wsh u hppy anant chaturdashi pray god fr ur pr...        23   \n",
       "182462  monsta_x beautiful jap v mv teaser monseutaegs...        16   \n",
       "166434  kg multistarrer oso multistarrer ce bcoz dp ro...        20   \n",
       "286018  mets lineup v dbacks nimmo cf cabrera b confor...        22   \n",
       "\n",
       "        len_tokens  \n",
       "410022          40  \n",
       "193963          40  \n",
       "182462          40  \n",
       "166434          39  \n",
       "286018          39  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of any excessive tokenization tweet\n",
    "tweets_test = tweets_test.iloc[12:]\n",
    "tweets_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Index\n",
    "tweets_test = tweets_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy             414631\n",
       "anticipation    214284\n",
       "trust           169876\n",
       "sadness         156859\n",
       "disgust         118381\n",
       "fear             45451\n",
       "surprise         38980\n",
       "anger            34836\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train['emotion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train['emotion'] = tweets_train['emotion'].map({'joy':0, 'anticipation':1, 'trust':2, 'sadness':3, 'disgust':4, 'fear':5, 'surprise':6, 'anger':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    414631\n",
       "1    214284\n",
       "2    169876\n",
       "3    156859\n",
       "4    118381\n",
       "5     45451\n",
       "6     38980\n",
       "7     34836\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['joy', 'anticipation', 'trust', 'sadness', 'disgust', 'fear', 'surprise', 'anger']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_index = dict((c, i) for i, c in enumerate(classes))\n",
    "index_to_classes = dict((v, k) for k, v in classes_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joy': 0,\n",
       " 'anticipation': 1,\n",
       " 'trust': 2,\n",
       " 'sadness': 3,\n",
       " 'disgust': 4,\n",
       " 'fear': 5,\n",
       " 'surprise': 6,\n",
       " 'anger': 7}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'joy',\n",
       " 1: 'anticipation',\n",
       " 2: 'trust',\n",
       " 3: 'sadness',\n",
       " 4: 'disgust',\n",
       " 5: 'fear',\n",
       " 6: 'surprise',\n",
       " 7: 'anger'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to convert string values to numeric values to be used in training along with the padded data.\n",
    "names_to_ids = lambda labels: np.array([classes_to_index.get(x) for x in labels])\n",
    "ids_to_names = lambda labels: np.array([index_to_classes.get(x) for x in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Class Balancing and Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "train_x, train_y = ros.fit_resample(np.array(tweets_train['clean_text']).reshape(-1, 1), np.array(tweets_train['emotion']).reshape(-1, 1));\n",
    "train_pad = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['clean_text', 'emotion']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    414631\n",
       "5    414631\n",
       "6    414631\n",
       "3    414631\n",
       "1    414631\n",
       "0    414631\n",
       "2    414631\n",
       "7    414631\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would continue buy season ticket ref chump</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>china allow business country america new chine...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distraction distract trumprussia trumpcrimefam...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>student unprepared disengage exhaust teacherlife</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>always never let anyone destroy yourdreams wou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  emotion\n",
       "0         would continue buy season ticket ref chump        4\n",
       "1  china allow business country america new chine...        5\n",
       "2  distraction distract trumprussia trumpcrimefam...        6\n",
       "3   student unprepared disengage exhaust teacherlife        3\n",
       "4  always never let anyone destroy yourdreams wou...        1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating variables to use in train_test_split\n",
    "X = train_pad['clean_text'].values\n",
    "Y = train_pad['emotion'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side note shout w presence audience kudos rock bizgalz hesm\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[50])\n",
    "print(y_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "tweets_pred_test = tweets_test['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "god name use strong head tail misuse weak break stupid use name\n"
     ]
    }
   ],
   "source": [
    "print(tweets_pred_test[50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#During the process of creating and deleting my many models, one hot encoding provide more accurate results\n",
    "from sklearn import preprocessing\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder()\n",
    "y_train = ohe.fit_transform(np.array(y_train, dtype=object).reshape(-1, 1)).toarray()\n",
    "y_valid = ohe.fit_transform(np.array(y_test, dtype=object).reshape(-1, 1)).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Bert Modeling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Encoding_Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_max=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Bert.Encode_Plus\n",
    "def tokenize(data,max_len=len_max) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i in range(len(data)):\n",
    "        encoded = bert_tokenizer.encode_plus(\n",
    "            data[i],\n",
    "            add_special_tokens=True,\n",
    "            max_length=len_max,\n",
    "            padding='max_length',\n",
    "            #return_tensors='tf',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    #input_ids = tf.convert_to_tensor(input_ids)\n",
    "    #attention_masks = tf.convert_to_tensor(attention_masks)\n",
    "\n",
    "    return np.array(input_ids, dtype =np.int32),np.array(attention_masks, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['big sister always see eye eye come kid always look raisinghandsmedium darkskintone faceblowingakiss revolvinghearts thankful','This is a Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "idTest, masktTest = tokenize(test, len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 101, 2023, 2003, 1037, 3231,  102,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idTest[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "inTestTensor =tf.convert_to_tensor(idTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
       "array([[  101,  2502,  2905,  2467,  2156,  3239,  3239,  2272,  4845,\n",
       "         2467,  2298,  6274, 11774,  6491,  2098,  5007,  2601, 29334,\n",
       "         5524,  2227, 16558, 14138,  8978,  4757, 24135, 22375,  2015,\n",
       "        18836,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  101,  2023,  2003,  1037,  3231,   102,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inTestTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inid, train_attmask = tokenize(X_train, len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inid, val_attmask = tokenize(X_test, len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inid, test_attmask = tokenize(tweets_pred_test, len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_inid, train_attmask = tokenize(X_train, len_max)\n",
    "# val_inid, val_attmask = tokenize(X_test, len_max)\n",
    "# test_inid, test_attmask = tokenize(tweets_pred_test, len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_inid_tf = tf.convert_to_tensor(train_inid)\n",
    "# train_attmask_tf = tf.convert_to_tensor(train_attmask)\n",
    "# val_inid_tf = tf.convert_to_tensor(val_inid)\n",
    "# val_attmask_tf = tf.convert_to_tensor(val_attmask)\n",
    "# test_inid_tf = tf.convert_to_tensor(test_inid)\n",
    "# test_attmask_tf = tf.convert_to_tensor(test_attmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n",
      "                                thPoolingAndCrossAt               'input_2[0][0]']                \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 8)            6152        ['tf_bert_model[0][1]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,488,392\n",
      "Trainable params: 109,488,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-7)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "\n",
    "input_ids = tf.keras.Input(shape=(len_max,),dtype='int32')\n",
    "attention_masks = tf.keras.Input(shape=(len_max,),dtype='int32')\n",
    "embeddings = bert_model([input_ids,attention_masks])[1]\n",
    "output = tf.keras.layers.Dense(8, activation=\"softmax\")(embeddings)\n",
    "\n",
    "model = tf.keras.models.Model(inputs = [input_ids,attention_masks], outputs = output)\n",
    "\n",
    "model.compile(opt, loss=loss, metrics=accuracy)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "callbacks_list = [tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=1,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1205/331705 [..............................] - ETA: 31:29:46 - loss: 1.8627 - categorical_accuracy: 0.2783"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history_bert \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_inid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_attmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_inid\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_attmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_bert = model.fit([train_inid, train_attmask], y_train, \n",
    "                         validation_data=([val_inid,val_attmask], y_valid), \n",
    "                         epochs=10,\n",
    "                         batch_size=8,\n",
    "                         callbacks = callbacks_list\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Tokenization\n",
    "As mentioned before, certain decision were decided due to the speed of how things could be. Here is where that started, with usage of Tensorflow, Keras, and trying to make code that make things faster but instead made things longer. I decided to go with the Keras Tokenization as I was able to set a limit of words to be used, as well as it being very compatible with padding. This solution performed well as it was able to still provided a relatively decent accuracy predicition overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels were set and functions were created that could easily convert the emotions to a value to be used in the training of the model and convert those values back to string.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION\n",
    "#### Genuinely just relied on Google for the formatting and trial and error.\n",
    "Model was created based on RNN and utilized the Keras Layers to aid with long-form content by using LSTM to mitigate the initial proplems with RNN which is it's potentially to lean towards improper weight gradients when it comes to large data looping too much and messing with the weight values.\n",
    "With all that being said, even without pre-processing it still performed relatively well. The Original Training of the Model was done at batches of 64, to save time and Epochs of 25. The 64, which is larger than the usual 32, may have been faster but could have impacted accuracy as well. As such, in the second round with the preprocessed data, it was changed to 32 and 10. The model utilize Keras embedding and layers to create an RNN that checks for meaning withing the word and related words of the twitter. The LSTM allows for the RNN to avoid looping too much and messing with the ability to validate data properly. The Dense is amount to amount of emotions and utilize softmax for the predicted results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "No validation data sure made things interesting.\n",
    "Original Training = 18/25 Epoch for Batches of 64.\n",
    "Current = 10 Epoch for Batches of 32.\n",
    "There was an issue whereby the predit function did not produce the desired results and I thought the model was wrong. However, it turned out I was using an outdated TensorFlow model function and I have learned the importance of reading a Module information and formatting. The working model produce a single value which is then converted from index_to_ids from the previously created function. The most optimal set of intructions and parameter are what we have now in this document. \n",
    "\n",
    "The various versions were tested on a 1 Epoch basis, and the current model, the No Pre-Processing Model consistently placed the best. In order of Performance, the other ones were Model With Stop Words and Demojize Include and the Last was the Pre-Processing Model that got rid of most things.\n",
    "\n",
    "That being said, while this first model was indeed the best, by working with the other models I was able narrow down the num_words, length, and epochs for more or less the best performance I could do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predicting\n",
    "pred = np.argmax(model.predict([test_inid,test_attmask]), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape, tweets_test_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Prediction index to name and comparing test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_result = ids_to_names(pred)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_test[50])\n",
    "print(pred_result[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'id': twitTest_df.tweet_id, 'emotion': pred_result})\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Model outperforms other Pre-Processing Models but not the Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
